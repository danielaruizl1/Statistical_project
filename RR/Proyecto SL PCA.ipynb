{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Statistical Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ydata-profiling in c:\\users\\danie\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: scipy<1.12,>=1.4.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.10.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<2.1,>1.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.5.3)\n",
      "Requirement already satisfied: matplotlib<=3.7.3,>=3.2 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (3.7.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.10.13)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (6.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (3.1.2)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.5 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.7.5)\n",
      "Requirement already satisfied: numpy<1.26,>=1.16.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.24.3)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.12.3)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.12.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.10)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.14.0)\n",
      "Requirement already satisfied: typeguard<5,>=4.1.2 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (4.1.5)\n",
      "Requirement already satisfied: imagehash==4.3.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.9.2)\n",
      "Requirement already satisfied: dacite>=1.8 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.8.1)\n",
      "Requirement already satisfied: numba<0.59.0,>=0.56.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.57.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\danie\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling) (1.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\danie\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling) (9.4.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (22.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (3.1)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from numba<0.59.0,>=0.56.0->ydata-profiling) (0.40.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<2.1,>1.1->ydata-profiling) (2022.7)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from pydantic<2,>=1.8.1->ydata-profiling) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (2023.7.22)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\danie\\anaconda3\\lib\\site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\anaconda3\\lib\\site-packages (from tqdm<5,>=4.48.2->ydata-profiling) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\danie\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras import backend as K\n",
    "from keras import applications, models\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import optuna\n",
    "\n",
    "#Librerías extras\n",
    "import itertools\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "      <th>V88</th>\n",
       "      <th>V89</th>\n",
       "      <th>V90</th>\n",
       "      <th>V91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>44.81144</td>\n",
       "      <td>0.83826</td>\n",
       "      <td>0</td>\n",
       "      <td>7.91314</td>\n",
       "      <td>10.94148</td>\n",
       "      <td>-0.04547</td>\n",
       "      <td>-15.16332</td>\n",
       "      <td>-10.47324</td>\n",
       "      <td>14.17212</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.44873</td>\n",
       "      <td>-230.30484</td>\n",
       "      <td>-40.94698</td>\n",
       "      <td>48.20025</td>\n",
       "      <td>-0.28694</td>\n",
       "      <td>155.76251</td>\n",
       "      <td>-56.23579</td>\n",
       "      <td>13.62599</td>\n",
       "      <td>123.92018</td>\n",
       "      <td>10.02845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>41.99180</td>\n",
       "      <td>7.99976</td>\n",
       "      <td>0</td>\n",
       "      <td>64.26707</td>\n",
       "      <td>16.54115</td>\n",
       "      <td>-9.28737</td>\n",
       "      <td>-40.73524</td>\n",
       "      <td>33.60440</td>\n",
       "      <td>9.18802</td>\n",
       "      <td>...</td>\n",
       "      <td>18.68972</td>\n",
       "      <td>-44.06062</td>\n",
       "      <td>52.37792</td>\n",
       "      <td>81.36093</td>\n",
       "      <td>-14.81111</td>\n",
       "      <td>151.66273</td>\n",
       "      <td>-120.61213</td>\n",
       "      <td>10.57519</td>\n",
       "      <td>-3.21078</td>\n",
       "      <td>-1.07438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>42.19196</td>\n",
       "      <td>2.23111</td>\n",
       "      <td>0</td>\n",
       "      <td>65.07719</td>\n",
       "      <td>24.99746</td>\n",
       "      <td>1.76100</td>\n",
       "      <td>6.66573</td>\n",
       "      <td>3.45778</td>\n",
       "      <td>-24.42779</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.69878</td>\n",
       "      <td>-118.95712</td>\n",
       "      <td>54.15529</td>\n",
       "      <td>-23.32168</td>\n",
       "      <td>-9.65067</td>\n",
       "      <td>-83.83055</td>\n",
       "      <td>-141.17594</td>\n",
       "      <td>7.33084</td>\n",
       "      <td>-275.69714</td>\n",
       "      <td>2.35522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>39.28634</td>\n",
       "      <td>-1.85716</td>\n",
       "      <td>0</td>\n",
       "      <td>91.04190</td>\n",
       "      <td>9.08333</td>\n",
       "      <td>0.08502</td>\n",
       "      <td>-5.59216</td>\n",
       "      <td>65.62463</td>\n",
       "      <td>8.33105</td>\n",
       "      <td>...</td>\n",
       "      <td>20.89044</td>\n",
       "      <td>-18.53135</td>\n",
       "      <td>176.09769</td>\n",
       "      <td>351.33669</td>\n",
       "      <td>3.44682</td>\n",
       "      <td>121.69156</td>\n",
       "      <td>-270.43989</td>\n",
       "      <td>12.51659</td>\n",
       "      <td>-140.88884</td>\n",
       "      <td>-0.23476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>40.36025</td>\n",
       "      <td>2.94918</td>\n",
       "      <td>0</td>\n",
       "      <td>53.83723</td>\n",
       "      <td>13.71369</td>\n",
       "      <td>-8.21964</td>\n",
       "      <td>-40.21636</td>\n",
       "      <td>21.22366</td>\n",
       "      <td>17.16742</td>\n",
       "      <td>...</td>\n",
       "      <td>19.91979</td>\n",
       "      <td>34.59026</td>\n",
       "      <td>-69.83720</td>\n",
       "      <td>102.31946</td>\n",
       "      <td>8.08807</td>\n",
       "      <td>135.08089</td>\n",
       "      <td>-153.02327</td>\n",
       "      <td>4.09207</td>\n",
       "      <td>-68.33046</td>\n",
       "      <td>-6.19159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     V1        V2       V3  V4        V5        V6       V7        V8  \\\n",
       "0  2013  44.81144  0.83826   0   7.91314  10.94148 -0.04547 -15.16332   \n",
       "1  1998  41.99180  7.99976   0  64.26707  16.54115 -9.28737 -40.73524   \n",
       "2  1998  42.19196  2.23111   0  65.07719  24.99746  1.76100   6.66573   \n",
       "3  1998  39.28634 -1.85716   0  91.04190   9.08333  0.08502  -5.59216   \n",
       "4  1998  40.36025  2.94918   0  53.83723  13.71369 -8.21964 -40.21636   \n",
       "\n",
       "         V9       V10  ...       V82        V83        V84        V85  \\\n",
       "0 -10.47324  14.17212  ...  -8.44873 -230.30484  -40.94698   48.20025   \n",
       "1  33.60440   9.18802  ...  18.68972  -44.06062   52.37792   81.36093   \n",
       "2   3.45778 -24.42779  ...  -3.69878 -118.95712   54.15529  -23.32168   \n",
       "3  65.62463   8.33105  ...  20.89044  -18.53135  176.09769  351.33669   \n",
       "4  21.22366  17.16742  ...  19.91979   34.59026  -69.83720  102.31946   \n",
       "\n",
       "        V86        V87        V88       V89        V90       V91  \n",
       "0  -0.28694  155.76251  -56.23579  13.62599  123.92018  10.02845  \n",
       "1 -14.81111  151.66273 -120.61213  10.57519   -3.21078  -1.07438  \n",
       "2  -9.65067  -83.83055 -141.17594   7.33084 -275.69714   2.35522  \n",
       "3   3.44682  121.69156 -270.43989  12.51659 -140.88884  -0.23476  \n",
       "4   8.08807  135.08089 -153.02327   4.09207  -68.33046  -6.19159  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'C:/Users/danie/OneDrive - Universidad de los andes/Doctorado/Statistical learning/Proyecto/trainReg.txt'\n",
    "data = pd.read_csv(file)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "      <th>V88</th>\n",
       "      <th>V89</th>\n",
       "      <th>V90</th>\n",
       "      <th>V91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.81144</td>\n",
       "      <td>0.83826</td>\n",
       "      <td>7.91314</td>\n",
       "      <td>10.94148</td>\n",
       "      <td>-0.04547</td>\n",
       "      <td>-15.16332</td>\n",
       "      <td>-10.47324</td>\n",
       "      <td>14.17212</td>\n",
       "      <td>10.57382</td>\n",
       "      <td>-11.21128</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.44873</td>\n",
       "      <td>-230.30484</td>\n",
       "      <td>-40.94698</td>\n",
       "      <td>48.20025</td>\n",
       "      <td>-0.28694</td>\n",
       "      <td>155.76251</td>\n",
       "      <td>-56.23579</td>\n",
       "      <td>13.62599</td>\n",
       "      <td>123.92018</td>\n",
       "      <td>10.02845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.99180</td>\n",
       "      <td>7.99976</td>\n",
       "      <td>64.26707</td>\n",
       "      <td>16.54115</td>\n",
       "      <td>-9.28737</td>\n",
       "      <td>-40.73524</td>\n",
       "      <td>33.60440</td>\n",
       "      <td>9.18802</td>\n",
       "      <td>-6.79144</td>\n",
       "      <td>44.21327</td>\n",
       "      <td>...</td>\n",
       "      <td>18.68972</td>\n",
       "      <td>-44.06062</td>\n",
       "      <td>52.37792</td>\n",
       "      <td>81.36093</td>\n",
       "      <td>-14.81111</td>\n",
       "      <td>151.66273</td>\n",
       "      <td>-120.61213</td>\n",
       "      <td>10.57519</td>\n",
       "      <td>-3.21078</td>\n",
       "      <td>-1.07438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.19196</td>\n",
       "      <td>2.23111</td>\n",
       "      <td>65.07719</td>\n",
       "      <td>24.99746</td>\n",
       "      <td>1.76100</td>\n",
       "      <td>6.66573</td>\n",
       "      <td>3.45778</td>\n",
       "      <td>-24.42779</td>\n",
       "      <td>-18.45069</td>\n",
       "      <td>233.16766</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.69878</td>\n",
       "      <td>-118.95712</td>\n",
       "      <td>54.15529</td>\n",
       "      <td>-23.32168</td>\n",
       "      <td>-9.65067</td>\n",
       "      <td>-83.83055</td>\n",
       "      <td>-141.17594</td>\n",
       "      <td>7.33084</td>\n",
       "      <td>-275.69714</td>\n",
       "      <td>2.35522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.28634</td>\n",
       "      <td>-1.85716</td>\n",
       "      <td>91.04190</td>\n",
       "      <td>9.08333</td>\n",
       "      <td>0.08502</td>\n",
       "      <td>-5.59216</td>\n",
       "      <td>65.62463</td>\n",
       "      <td>8.33105</td>\n",
       "      <td>11.70269</td>\n",
       "      <td>79.90772</td>\n",
       "      <td>...</td>\n",
       "      <td>20.89044</td>\n",
       "      <td>-18.53135</td>\n",
       "      <td>176.09769</td>\n",
       "      <td>351.33669</td>\n",
       "      <td>3.44682</td>\n",
       "      <td>121.69156</td>\n",
       "      <td>-270.43989</td>\n",
       "      <td>12.51659</td>\n",
       "      <td>-140.88884</td>\n",
       "      <td>-0.23476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.36025</td>\n",
       "      <td>2.94918</td>\n",
       "      <td>53.83723</td>\n",
       "      <td>13.71369</td>\n",
       "      <td>-8.21964</td>\n",
       "      <td>-40.21636</td>\n",
       "      <td>21.22366</td>\n",
       "      <td>17.16742</td>\n",
       "      <td>0.14463</td>\n",
       "      <td>72.23955</td>\n",
       "      <td>...</td>\n",
       "      <td>19.91979</td>\n",
       "      <td>34.59026</td>\n",
       "      <td>-69.83720</td>\n",
       "      <td>102.31946</td>\n",
       "      <td>8.08807</td>\n",
       "      <td>135.08089</td>\n",
       "      <td>-153.02327</td>\n",
       "      <td>4.09207</td>\n",
       "      <td>-68.33046</td>\n",
       "      <td>-6.19159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77774</th>\n",
       "      <td>33.76706</td>\n",
       "      <td>-3.80678</td>\n",
       "      <td>-1.44169</td>\n",
       "      <td>23.78801</td>\n",
       "      <td>5.01781</td>\n",
       "      <td>1.58966</td>\n",
       "      <td>-25.02281</td>\n",
       "      <td>25.90399</td>\n",
       "      <td>19.87408</td>\n",
       "      <td>-21.41492</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.84706</td>\n",
       "      <td>-637.31267</td>\n",
       "      <td>-174.93600</td>\n",
       "      <td>127.32951</td>\n",
       "      <td>-15.75226</td>\n",
       "      <td>-144.64697</td>\n",
       "      <td>6.53731</td>\n",
       "      <td>5.54065</td>\n",
       "      <td>193.68594</td>\n",
       "      <td>32.75930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77775</th>\n",
       "      <td>25.77805</td>\n",
       "      <td>2.41861</td>\n",
       "      <td>5.96418</td>\n",
       "      <td>-8.43658</td>\n",
       "      <td>-1.36182</td>\n",
       "      <td>2.51784</td>\n",
       "      <td>-18.57770</td>\n",
       "      <td>-25.69885</td>\n",
       "      <td>9.97971</td>\n",
       "      <td>-100.96885</td>\n",
       "      <td>...</td>\n",
       "      <td>27.76376</td>\n",
       "      <td>-44.59643</td>\n",
       "      <td>-116.15080</td>\n",
       "      <td>-34.33917</td>\n",
       "      <td>4.86612</td>\n",
       "      <td>141.37999</td>\n",
       "      <td>282.57252</td>\n",
       "      <td>23.32459</td>\n",
       "      <td>125.07389</td>\n",
       "      <td>-19.16268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77776</th>\n",
       "      <td>24.78656</td>\n",
       "      <td>1.36415</td>\n",
       "      <td>34.13329</td>\n",
       "      <td>34.32996</td>\n",
       "      <td>-0.95170</td>\n",
       "      <td>75.33572</td>\n",
       "      <td>-28.59028</td>\n",
       "      <td>-31.86076</td>\n",
       "      <td>-4.06444</td>\n",
       "      <td>-53.17960</td>\n",
       "      <td>...</td>\n",
       "      <td>33.73262</td>\n",
       "      <td>-206.05602</td>\n",
       "      <td>44.10029</td>\n",
       "      <td>-635.01673</td>\n",
       "      <td>-16.75481</td>\n",
       "      <td>114.74225</td>\n",
       "      <td>-192.79351</td>\n",
       "      <td>-4.44202</td>\n",
       "      <td>1457.72692</td>\n",
       "      <td>-50.93615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77777</th>\n",
       "      <td>39.67698</td>\n",
       "      <td>3.65167</td>\n",
       "      <td>34.04925</td>\n",
       "      <td>-0.68467</td>\n",
       "      <td>-2.13911</td>\n",
       "      <td>-5.70096</td>\n",
       "      <td>-10.57862</td>\n",
       "      <td>-1.30048</td>\n",
       "      <td>9.85726</td>\n",
       "      <td>7.33263</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.46611</td>\n",
       "      <td>-117.84462</td>\n",
       "      <td>139.93465</td>\n",
       "      <td>67.70637</td>\n",
       "      <td>-24.18488</td>\n",
       "      <td>-39.54694</td>\n",
       "      <td>185.26251</td>\n",
       "      <td>-1.37534</td>\n",
       "      <td>216.14774</td>\n",
       "      <td>-12.75066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77778</th>\n",
       "      <td>44.44499</td>\n",
       "      <td>8.89481</td>\n",
       "      <td>48.99411</td>\n",
       "      <td>15.83343</td>\n",
       "      <td>5.00566</td>\n",
       "      <td>-23.89831</td>\n",
       "      <td>-21.12626</td>\n",
       "      <td>-12.13135</td>\n",
       "      <td>12.76931</td>\n",
       "      <td>-44.42589</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.07718</td>\n",
       "      <td>-623.88638</td>\n",
       "      <td>186.93061</td>\n",
       "      <td>-9.41335</td>\n",
       "      <td>-11.51320</td>\n",
       "      <td>137.13883</td>\n",
       "      <td>-80.15732</td>\n",
       "      <td>20.33014</td>\n",
       "      <td>106.69048</td>\n",
       "      <td>6.68635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77779 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V2       V3        V5        V6       V7        V8        V9  \\\n",
       "0      44.81144  0.83826   7.91314  10.94148 -0.04547 -15.16332 -10.47324   \n",
       "1      41.99180  7.99976  64.26707  16.54115 -9.28737 -40.73524  33.60440   \n",
       "2      42.19196  2.23111  65.07719  24.99746  1.76100   6.66573   3.45778   \n",
       "3      39.28634 -1.85716  91.04190   9.08333  0.08502  -5.59216  65.62463   \n",
       "4      40.36025  2.94918  53.83723  13.71369 -8.21964 -40.21636  21.22366   \n",
       "...         ...      ...       ...       ...      ...       ...       ...   \n",
       "77774  33.76706 -3.80678  -1.44169  23.78801  5.01781   1.58966 -25.02281   \n",
       "77775  25.77805  2.41861   5.96418  -8.43658 -1.36182   2.51784 -18.57770   \n",
       "77776  24.78656  1.36415  34.13329  34.32996 -0.95170  75.33572 -28.59028   \n",
       "77777  39.67698  3.65167  34.04925  -0.68467 -2.13911  -5.70096 -10.57862   \n",
       "77778  44.44499  8.89481  48.99411  15.83343  5.00566 -23.89831 -21.12626   \n",
       "\n",
       "            V10       V11        V12  ...       V82        V83        V84  \\\n",
       "0      14.17212  10.57382  -11.21128  ...  -8.44873 -230.30484  -40.94698   \n",
       "1       9.18802  -6.79144   44.21327  ...  18.68972  -44.06062   52.37792   \n",
       "2     -24.42779 -18.45069  233.16766  ...  -3.69878 -118.95712   54.15529   \n",
       "3       8.33105  11.70269   79.90772  ...  20.89044  -18.53135  176.09769   \n",
       "4      17.16742   0.14463   72.23955  ...  19.91979   34.59026  -69.83720   \n",
       "...         ...       ...        ...  ...       ...        ...        ...   \n",
       "77774  25.90399  19.87408  -21.41492  ... -36.84706 -637.31267 -174.93600   \n",
       "77775 -25.69885   9.97971 -100.96885  ...  27.76376  -44.59643 -116.15080   \n",
       "77776 -31.86076  -4.06444  -53.17960  ...  33.73262 -206.05602   44.10029   \n",
       "77777  -1.30048   9.85726    7.33263  ... -15.46611 -117.84462  139.93465   \n",
       "77778 -12.13135  12.76931  -44.42589  ...  -9.07718 -623.88638  186.93061   \n",
       "\n",
       "             V85       V86        V87        V88       V89         V90  \\\n",
       "0       48.20025  -0.28694  155.76251  -56.23579  13.62599   123.92018   \n",
       "1       81.36093 -14.81111  151.66273 -120.61213  10.57519    -3.21078   \n",
       "2      -23.32168  -9.65067  -83.83055 -141.17594   7.33084  -275.69714   \n",
       "3      351.33669   3.44682  121.69156 -270.43989  12.51659  -140.88884   \n",
       "4      102.31946   8.08807  135.08089 -153.02327   4.09207   -68.33046   \n",
       "...          ...       ...        ...        ...       ...         ...   \n",
       "77774  127.32951 -15.75226 -144.64697    6.53731   5.54065   193.68594   \n",
       "77775  -34.33917   4.86612  141.37999  282.57252  23.32459   125.07389   \n",
       "77776 -635.01673 -16.75481  114.74225 -192.79351  -4.44202  1457.72692   \n",
       "77777   67.70637 -24.18488  -39.54694  185.26251  -1.37534   216.14774   \n",
       "77778   -9.41335 -11.51320  137.13883  -80.15732  20.33014   106.69048   \n",
       "\n",
       "            V91  \n",
       "0      10.02845  \n",
       "1      -1.07438  \n",
       "2       2.35522  \n",
       "3      -0.23476  \n",
       "4      -6.19159  \n",
       "...         ...  \n",
       "77774  32.75930  \n",
       "77775 -19.16268  \n",
       "77776 -50.93615  \n",
       "77777 -12.75066  \n",
       "77778   6.68635  \n",
       "\n",
       "[77779 rows x 89 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = data.drop(['V1', 'V4'], axis = 1), data['V1']\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "      <th>V88</th>\n",
       "      <th>V89</th>\n",
       "      <th>V90</th>\n",
       "      <th>V91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.74170</td>\n",
       "      <td>0.86615</td>\n",
       "      <td>1.44450</td>\n",
       "      <td>-13.87834</td>\n",
       "      <td>-9.57602</td>\n",
       "      <td>5.89475</td>\n",
       "      <td>-4.46036</td>\n",
       "      <td>-10.60501</td>\n",
       "      <td>-2.20779</td>\n",
       "      <td>-31.56674</td>\n",
       "      <td>...</td>\n",
       "      <td>10.78210</td>\n",
       "      <td>-183.63792</td>\n",
       "      <td>131.18868</td>\n",
       "      <td>37.68626</td>\n",
       "      <td>-4.48926</td>\n",
       "      <td>10.98139</td>\n",
       "      <td>-48.14549</td>\n",
       "      <td>-7.27992</td>\n",
       "      <td>-54.52826</td>\n",
       "      <td>4.81414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.31664</td>\n",
       "      <td>-0.47799</td>\n",
       "      <td>-12.27958</td>\n",
       "      <td>-29.32847</td>\n",
       "      <td>-2.38610</td>\n",
       "      <td>-7.27386</td>\n",
       "      <td>-1.87712</td>\n",
       "      <td>-3.74953</td>\n",
       "      <td>-3.38237</td>\n",
       "      <td>1.54788</td>\n",
       "      <td>...</td>\n",
       "      <td>53.92478</td>\n",
       "      <td>-238.77713</td>\n",
       "      <td>134.28149</td>\n",
       "      <td>81.19403</td>\n",
       "      <td>-4.81669</td>\n",
       "      <td>106.00178</td>\n",
       "      <td>3.34940</td>\n",
       "      <td>2.72328</td>\n",
       "      <td>156.94894</td>\n",
       "      <td>-8.44873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.25032</td>\n",
       "      <td>-6.31920</td>\n",
       "      <td>-2.56469</td>\n",
       "      <td>-7.59368</td>\n",
       "      <td>2.12862</td>\n",
       "      <td>23.29535</td>\n",
       "      <td>-0.34225</td>\n",
       "      <td>4.48761</td>\n",
       "      <td>4.93676</td>\n",
       "      <td>33.62086</td>\n",
       "      <td>...</td>\n",
       "      <td>40.95711</td>\n",
       "      <td>-269.59803</td>\n",
       "      <td>69.88747</td>\n",
       "      <td>29.65701</td>\n",
       "      <td>-0.12854</td>\n",
       "      <td>106.92919</td>\n",
       "      <td>-62.86550</td>\n",
       "      <td>30.12278</td>\n",
       "      <td>24.39843</td>\n",
       "      <td>-10.68316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.94220</td>\n",
       "      <td>-4.12303</td>\n",
       "      <td>-15.79205</td>\n",
       "      <td>7.15794</td>\n",
       "      <td>1.46007</td>\n",
       "      <td>-3.38280</td>\n",
       "      <td>-8.48270</td>\n",
       "      <td>12.69732</td>\n",
       "      <td>-1.68102</td>\n",
       "      <td>3.62442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81574</td>\n",
       "      <td>-243.09497</td>\n",
       "      <td>24.20334</td>\n",
       "      <td>-10.02719</td>\n",
       "      <td>19.25667</td>\n",
       "      <td>66.15602</td>\n",
       "      <td>-64.78646</td>\n",
       "      <td>9.09148</td>\n",
       "      <td>11.46055</td>\n",
       "      <td>-7.12136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.40813</td>\n",
       "      <td>-1.52061</td>\n",
       "      <td>-10.10142</td>\n",
       "      <td>-17.74876</td>\n",
       "      <td>-5.96768</td>\n",
       "      <td>-29.94136</td>\n",
       "      <td>-11.84237</td>\n",
       "      <td>5.90144</td>\n",
       "      <td>3.95996</td>\n",
       "      <td>6.07786</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.58634</td>\n",
       "      <td>-61.67109</td>\n",
       "      <td>47.53814</td>\n",
       "      <td>139.04916</td>\n",
       "      <td>6.85904</td>\n",
       "      <td>-57.09356</td>\n",
       "      <td>-49.57683</td>\n",
       "      <td>-6.61453</td>\n",
       "      <td>22.55497</td>\n",
       "      <td>-4.39272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18652</th>\n",
       "      <td>47.13482</td>\n",
       "      <td>3.84421</td>\n",
       "      <td>10.65084</td>\n",
       "      <td>6.76621</td>\n",
       "      <td>-7.62802</td>\n",
       "      <td>3.94229</td>\n",
       "      <td>-17.54994</td>\n",
       "      <td>-1.50402</td>\n",
       "      <td>1.28472</td>\n",
       "      <td>-0.39388</td>\n",
       "      <td>...</td>\n",
       "      <td>6.79574</td>\n",
       "      <td>50.40788</td>\n",
       "      <td>-208.86022</td>\n",
       "      <td>4.07771</td>\n",
       "      <td>22.98125</td>\n",
       "      <td>7.57026</td>\n",
       "      <td>-24.53948</td>\n",
       "      <td>-10.50575</td>\n",
       "      <td>-43.87160</td>\n",
       "      <td>-12.16460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18653</th>\n",
       "      <td>44.88535</td>\n",
       "      <td>1.21785</td>\n",
       "      <td>21.46818</td>\n",
       "      <td>6.06535</td>\n",
       "      <td>-3.21715</td>\n",
       "      <td>-49.46917</td>\n",
       "      <td>-4.24723</td>\n",
       "      <td>-11.95931</td>\n",
       "      <td>-7.80641</td>\n",
       "      <td>37.18960</td>\n",
       "      <td>...</td>\n",
       "      <td>23.74218</td>\n",
       "      <td>31.83756</td>\n",
       "      <td>100.18131</td>\n",
       "      <td>24.23003</td>\n",
       "      <td>-12.11153</td>\n",
       "      <td>-36.12918</td>\n",
       "      <td>-75.12454</td>\n",
       "      <td>-8.55251</td>\n",
       "      <td>-68.83852</td>\n",
       "      <td>16.46255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18654</th>\n",
       "      <td>49.12753</td>\n",
       "      <td>0.02024</td>\n",
       "      <td>-2.47167</td>\n",
       "      <td>11.16809</td>\n",
       "      <td>6.98209</td>\n",
       "      <td>-31.67139</td>\n",
       "      <td>-24.20034</td>\n",
       "      <td>-3.32383</td>\n",
       "      <td>0.42367</td>\n",
       "      <td>39.16904</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.44803</td>\n",
       "      <td>-5.25300</td>\n",
       "      <td>-70.27796</td>\n",
       "      <td>-19.94830</td>\n",
       "      <td>-6.54688</td>\n",
       "      <td>-8.89722</td>\n",
       "      <td>-183.92335</td>\n",
       "      <td>14.82729</td>\n",
       "      <td>192.20814</td>\n",
       "      <td>32.05995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18655</th>\n",
       "      <td>47.07399</td>\n",
       "      <td>-2.12987</td>\n",
       "      <td>19.65870</td>\n",
       "      <td>7.44925</td>\n",
       "      <td>9.22878</td>\n",
       "      <td>-0.28598</td>\n",
       "      <td>5.97625</td>\n",
       "      <td>-5.43954</td>\n",
       "      <td>5.32756</td>\n",
       "      <td>28.76730</td>\n",
       "      <td>...</td>\n",
       "      <td>3.92133</td>\n",
       "      <td>143.43511</td>\n",
       "      <td>-1.45249</td>\n",
       "      <td>-24.09898</td>\n",
       "      <td>-2.44389</td>\n",
       "      <td>45.49691</td>\n",
       "      <td>59.01571</td>\n",
       "      <td>-0.00247</td>\n",
       "      <td>79.83971</td>\n",
       "      <td>7.36172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18656</th>\n",
       "      <td>45.93657</td>\n",
       "      <td>0.16199</td>\n",
       "      <td>-19.49991</td>\n",
       "      <td>12.83200</td>\n",
       "      <td>-8.79991</td>\n",
       "      <td>17.32559</td>\n",
       "      <td>-35.85872</td>\n",
       "      <td>-15.51939</td>\n",
       "      <td>11.97427</td>\n",
       "      <td>-9.30473</td>\n",
       "      <td>...</td>\n",
       "      <td>21.18688</td>\n",
       "      <td>-110.63226</td>\n",
       "      <td>-101.11562</td>\n",
       "      <td>-189.47922</td>\n",
       "      <td>-0.72287</td>\n",
       "      <td>76.50974</td>\n",
       "      <td>-162.09858</td>\n",
       "      <td>-9.29159</td>\n",
       "      <td>2.50809</td>\n",
       "      <td>-1.62172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18657 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V2       V3        V5        V6       V7        V8        V9  \\\n",
       "0      35.74170  0.86615   1.44450 -13.87834 -9.57602   5.89475  -4.46036   \n",
       "1      35.31664 -0.47799 -12.27958 -29.32847 -2.38610  -7.27386  -1.87712   \n",
       "2      43.25032 -6.31920  -2.56469  -7.59368  2.12862  23.29535  -0.34225   \n",
       "3      44.94220 -4.12303 -15.79205   7.15794  1.46007  -3.38280  -8.48270   \n",
       "4      50.40813 -1.52061 -10.10142 -17.74876 -5.96768 -29.94136 -11.84237   \n",
       "...         ...      ...       ...       ...      ...       ...       ...   \n",
       "18652  47.13482  3.84421  10.65084   6.76621 -7.62802   3.94229 -17.54994   \n",
       "18653  44.88535  1.21785  21.46818   6.06535 -3.21715 -49.46917  -4.24723   \n",
       "18654  49.12753  0.02024  -2.47167  11.16809  6.98209 -31.67139 -24.20034   \n",
       "18655  47.07399 -2.12987  19.65870   7.44925  9.22878  -0.28598   5.97625   \n",
       "18656  45.93657  0.16199 -19.49991  12.83200 -8.79991  17.32559 -35.85872   \n",
       "\n",
       "            V10       V11       V12  ...       V82        V83        V84  \\\n",
       "0     -10.60501  -2.20779 -31.56674  ...  10.78210 -183.63792  131.18868   \n",
       "1      -3.74953  -3.38237   1.54788  ...  53.92478 -238.77713  134.28149   \n",
       "2       4.48761   4.93676  33.62086  ...  40.95711 -269.59803   69.88747   \n",
       "3      12.69732  -1.68102   3.62442  ...   0.81574 -243.09497   24.20334   \n",
       "4       5.90144   3.95996   6.07786  ...  -3.58634  -61.67109   47.53814   \n",
       "...         ...       ...       ...  ...       ...        ...        ...   \n",
       "18652  -1.50402   1.28472  -0.39388  ...   6.79574   50.40788 -208.86022   \n",
       "18653 -11.95931  -7.80641  37.18960  ...  23.74218   31.83756  100.18131   \n",
       "18654  -3.32383   0.42367  39.16904  ...  -3.44803   -5.25300  -70.27796   \n",
       "18655  -5.43954   5.32756  28.76730  ...   3.92133  143.43511   -1.45249   \n",
       "18656 -15.51939  11.97427  -9.30473  ...  21.18688 -110.63226 -101.11562   \n",
       "\n",
       "             V85       V86        V87        V88       V89        V90  \\\n",
       "0       37.68626  -4.48926   10.98139  -48.14549  -7.27992  -54.52826   \n",
       "1       81.19403  -4.81669  106.00178    3.34940   2.72328  156.94894   \n",
       "2       29.65701  -0.12854  106.92919  -62.86550  30.12278   24.39843   \n",
       "3      -10.02719  19.25667   66.15602  -64.78646   9.09148   11.46055   \n",
       "4      139.04916   6.85904  -57.09356  -49.57683  -6.61453   22.55497   \n",
       "...          ...       ...        ...        ...       ...        ...   \n",
       "18652    4.07771  22.98125    7.57026  -24.53948 -10.50575  -43.87160   \n",
       "18653   24.23003 -12.11153  -36.12918  -75.12454  -8.55251  -68.83852   \n",
       "18654  -19.94830  -6.54688   -8.89722 -183.92335  14.82729  192.20814   \n",
       "18655  -24.09898  -2.44389   45.49691   59.01571  -0.00247   79.83971   \n",
       "18656 -189.47922  -0.72287   76.50974 -162.09858  -9.29159    2.50809   \n",
       "\n",
       "            V91  \n",
       "0       4.81414  \n",
       "1      -8.44873  \n",
       "2     -10.68316  \n",
       "3      -7.12136  \n",
       "4      -4.39272  \n",
       "...         ...  \n",
       "18652 -12.16460  \n",
       "18653  16.46255  \n",
       "18654  32.05995  \n",
       "18655   7.36172  \n",
       "18656  -1.62172  \n",
       "\n",
       "[18657 rows x 89 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_val = 'C:/Users/danie/OneDrive - Universidad de los andes/Doctorado/Statistical learning/Proyecto/testReg.txt'\n",
    "X_test = pd.read_csv(file_val)\n",
    "X_test = X_test.drop(['Id','V4'],axis=1)\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.63061066,   2.74256438,  -0.82643743, ...,  -0.19056771,\n",
       "         -0.08738883,  -0.14941678],\n",
       "       [  0.98528106,   3.560313  ,  -2.44626181, ...,  -0.4123608 ,\n",
       "         -0.49070657,  -0.87109893],\n",
       "       [ -2.210552  ,  -0.42951059,  -0.35838037, ...,   0.02107202,\n",
       "          0.03668975,   0.3817478 ],\n",
       "       ...,\n",
       "       [  2.28079932, -14.62940395,  -6.57474961, ...,   0.20339834,\n",
       "          0.61188087,  -0.05255218],\n",
       "       [  0.1655115 ,  -0.68149957,  -2.18873068, ...,   0.57601517,\n",
       "          0.42180815,  -0.20903774],\n",
       "       [  1.7098807 ,   2.33249506,  -4.76884479, ...,   0.25029047,\n",
       "         -0.2549693 ,   0.2873786 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crea un objeto PCA\n",
    "pca = PCA(n_components=None)  # Puedes especificar el número de componentes deseados si lo conoces\n",
    "\n",
    "# Aplica PCA a los datos\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza explicada por cada componente principal:\n",
      "[0.11930848 0.08020891 0.05809389 0.04111874 0.03749546 0.0285649\n",
      " 0.02459246 0.02287359 0.02113432 0.0206777  0.01933014 0.01866938\n",
      " 0.01829342 0.016872   0.01642573 0.01525505 0.01481694 0.01410972\n",
      " 0.01368881 0.01343025 0.01280297 0.01277203 0.01249149 0.0117793\n",
      " 0.01153878 0.01136667 0.01122615 0.01110677 0.01085868 0.0099989\n",
      " 0.00983419 0.00948164 0.00918595 0.00906709 0.00847784 0.00815133\n",
      " 0.00794115 0.00764739 0.00749225 0.0073217  0.00721033 0.00712931\n",
      " 0.00688042 0.00674687 0.00650604 0.00628813 0.00609898 0.00598083\n",
      " 0.00589434 0.00577961 0.00548673 0.00538444 0.00522553 0.00513668\n",
      " 0.00497527 0.00489001 0.00456945 0.00453343 0.00452699 0.00419654\n",
      " 0.00413279 0.00391681 0.0038939  0.0037678  0.00368239 0.00344661\n",
      " 0.00339443 0.00335994 0.00317965 0.00299042 0.00285962 0.00275695\n",
      " 0.00268036 0.00259133 0.00250557 0.00233811 0.00219992 0.00211931\n",
      " 0.00200411 0.00194296 0.00180185 0.00171595 0.00154931 0.00134287\n",
      " 0.00131069 0.0010595  0.00093424 0.0008282  0.00075233]\n",
      "\n",
      "Acumulación de varianza explicada:\n",
      "[0.11930848 0.19951739 0.25761128 0.29873002 0.33622548 0.36479038\n",
      " 0.38938284 0.41225643 0.43339075 0.45406844 0.47339859 0.49206797\n",
      " 0.51036139 0.52723339 0.54365912 0.55891417 0.5737311  0.58784082\n",
      " 0.60152963 0.61495988 0.62776285 0.64053488 0.65302637 0.66480567\n",
      " 0.67634445 0.68771111 0.69893727 0.71004404 0.72090272 0.73090162\n",
      " 0.74073581 0.75021745 0.7594034  0.76847049 0.77694833 0.78509967\n",
      " 0.79304081 0.8006882  0.80818045 0.81550215 0.82271249 0.82984179\n",
      " 0.83672221 0.84346908 0.84997511 0.85626324 0.86236223 0.86834306\n",
      " 0.8742374  0.88001701 0.88550374 0.89088818 0.89611371 0.90125039\n",
      " 0.90622566 0.91111567 0.91568511 0.92021855 0.92474554 0.92894207\n",
      " 0.93307486 0.93699168 0.94088557 0.94465337 0.94833576 0.95178237\n",
      " 0.9551768  0.95853674 0.96171639 0.96470682 0.96756644 0.97032338\n",
      " 0.97300375 0.97559508 0.97810065 0.98043876 0.98263868 0.98475799\n",
      " 0.9867621  0.98870506 0.99050691 0.99222287 0.99377217 0.99511504\n",
      " 0.99642573 0.99748523 0.99841947 0.99924767 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Varianza explicada por cada componente principal\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"Varianza explicada por cada componente principal:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "# Acumulación de varianza explicada\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "print(\"\\nAcumulación de varianza explicada:\")\n",
    "print(cumulative_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V2 = 0.12\n",
      "V3 = 0.20\n",
      "V5 = 0.26\n",
      "V6 = 0.30\n",
      "V7 = 0.34\n",
      "V8 = 0.36\n",
      "V9 = 0.39\n",
      "V10 = 0.41\n",
      "V11 = 0.43\n",
      "V12 = 0.45\n",
      "V13 = 0.47\n",
      "V14 = 0.49\n",
      "V15 = 0.51\n",
      "V16 = 0.53\n",
      "V17 = 0.54\n",
      "V18 = 0.56\n",
      "V19 = 0.57\n",
      "V20 = 0.59\n",
      "V21 = 0.60\n",
      "V22 = 0.61\n",
      "V23 = 0.63\n",
      "V24 = 0.64\n",
      "V25 = 0.65\n",
      "V26 = 0.66\n",
      "V27 = 0.68\n",
      "V28 = 0.69\n",
      "V29 = 0.70\n",
      "V30 = 0.71\n",
      "V31 = 0.72\n",
      "V32 = 0.73\n",
      "V33 = 0.74\n",
      "V34 = 0.75\n",
      "V35 = 0.76\n",
      "V36 = 0.77\n",
      "V37 = 0.78\n",
      "V38 = 0.79\n",
      "V39 = 0.79\n",
      "V40 = 0.80\n",
      "V41 = 0.81\n",
      "V42 = 0.82\n",
      "V43 = 0.82\n",
      "V44 = 0.83\n",
      "V45 = 0.84\n",
      "V46 = 0.84\n",
      "V47 = 0.85\n",
      "V48 = 0.86\n",
      "V49 = 0.86\n",
      "V50 = 0.87\n",
      "V51 = 0.87\n",
      "V52 = 0.88\n",
      "V53 = 0.89\n",
      "V54 = 0.89\n",
      "V55 = 0.90\n",
      "V56 = 0.90\n",
      "V57 = 0.91\n",
      "V58 = 0.91\n",
      "V59 = 0.92\n",
      "V60 = 0.92\n",
      "V61 = 0.92\n",
      "V62 = 0.93\n",
      "V63 = 0.93\n",
      "V64 = 0.94\n",
      "V65 = 0.94\n",
      "V66 = 0.94\n",
      "V67 = 0.95\n",
      "V68 = 0.95\n",
      "V69 = 0.96\n",
      "V70 = 0.96\n",
      "V71 = 0.96\n",
      "V72 = 0.96\n",
      "V73 = 0.97\n",
      "V74 = 0.97\n",
      "V75 = 0.97\n",
      "V76 = 0.98\n",
      "V77 = 0.98\n",
      "V78 = 0.98\n",
      "V79 = 0.98\n",
      "V80 = 0.98\n",
      "V81 = 0.99\n",
      "V82 = 0.99\n",
      "V83 = 0.99\n",
      "V84 = 0.99\n",
      "V85 = 0.99\n",
      "V86 = 1.00\n",
      "V87 = 1.00\n",
      "V88 = 1.00\n",
      "V89 = 1.00\n",
      "V90 = 1.00\n",
      "V91 = 1.00\n"
     ]
    }
   ],
   "source": [
    "coef = dict(zip(X_train.columns, cumulative_variance_ratio))\n",
    "for k,v in coef.items():\n",
    "    print(f'{k} = {v:,.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La característica \"V68\" supera el 95% de acumulación de varianza explicada.\n"
     ]
    }
   ],
   "source": [
    "umbral = 0.95\n",
    "\n",
    "for car, var in coef.items():\n",
    "    if var >= umbral:\n",
    "        print(f'La característica \"{car}\" supera el 95% de acumulación de varianza explicada.')\n",
    "        break  # Rompe el bucle cuando se encuentra la primera característica que cumple el umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crea un objeto PCA\n",
    "pca = PCA()\n",
    "\n",
    "# Ajusta PCA a los datos escalados\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Calcula la acumulación de la varianza explicada\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Trazar la acumulación de la varianza explicada\n",
    "plt.plot(cumulative_variance_ratio)\n",
    "plt.xlabel('Número de Componentes Principales')\n",
    "plt.ylabel('Acumulación de Varianza Explicada')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.63061068,   2.74256424,  -0.82643756, ...,  -0.0497404 ,\n",
       "         -0.1822427 ,   0.47960005],\n",
       "       [  0.98528096,   3.56031257,  -2.4462633 , ...,   0.70999568,\n",
       "         -0.82622009,  -0.13219929],\n",
       "       [ -2.21055207,  -0.42951054,  -0.35838169, ...,   0.05200692,\n",
       "         -0.52842205,  -0.42172087],\n",
       "       ...,\n",
       "       [  2.28079916, -14.62940461,  -6.57475212, ...,  -2.51976066,\n",
       "          1.23944727,  -1.04143153],\n",
       "       [  0.16551141,  -0.68149988,  -2.1887309 , ...,  -1.99952153,\n",
       "          2.61551637,   0.92738036],\n",
       "       [  1.70988079,   2.33249504,  -4.76884374, ...,  -1.14652925,\n",
       "          0.7043047 ,   0.21140549]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define el número deseado de componentes principales\n",
    "n_components_desired = 65  # Ajusta este valor según tus necesidades\n",
    "\n",
    "# Crea un nuevo objeto PCA con el número deseado de componentes\n",
    "pca = PCA(n_components=n_components_desired)\n",
    "\n",
    "# Aplica PCA nuevamente con el número deseado de componentes\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=5, n_estimators=154, n_jobs=-1, random_state=23)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=5, n_estimators=154, n_jobs=-1, random_state=23)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=5, n_estimators=154, n_jobs=-1, random_state=23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_for = RandomForestRegressor(n_estimators=154, max_depth=5 ,random_state=23, n_jobs=-1)\n",
    "\n",
    "Rand_for.fit(X_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error en el conjunto de prueba: 101.62\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = Rand_for.predict(X_pca)\n",
    "mse = mean_squared_error(y_train, y_pred_rf)\n",
    "print(f'Mean Squared Error en el conjunto de prueba: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-06 19:28:57,598] A new study created in memory with name: no-name-2cd49387-3641-421f-bba0-50b1b587b272\n",
      "[I 2023-12-06 19:29:15,792] Trial 0 finished with value: 115.37869015304406 and parameters: {'alpha': 21.274604626067003}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:29:39,344] Trial 1 finished with value: 115.37869015304406 and parameters: {'alpha': 84.84742823756936}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:30:01,405] Trial 2 finished with value: 115.37869015304406 and parameters: {'alpha': 39.85574126003662}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:30:18,902] Trial 3 finished with value: 115.37869015304406 and parameters: {'alpha': 38.54583033857411}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:30:35,233] Trial 4 finished with value: 115.37869015304406 and parameters: {'alpha': 32.515777644345185}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:30:51,605] Trial 5 finished with value: 115.37869015304406 and parameters: {'alpha': 53.209331585144255}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:31:07,997] Trial 6 finished with value: 115.37869015304406 and parameters: {'alpha': 31.125186479085656}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:31:24,433] Trial 7 finished with value: 115.37869015304406 and parameters: {'alpha': 26.464872107824124}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:31:41,573] Trial 8 finished with value: 115.37869015304406 and parameters: {'alpha': 76.10563813199526}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:31:58,881] Trial 9 finished with value: 115.37869015304406 and parameters: {'alpha': 31.92479302384522}. Best is trial 0 with value: 115.37869015304406.\n",
      "[I 2023-12-06 19:32:29,928] Trial 10 finished with value: 114.95615419719232 and parameters: {'alpha': 5.773034437984608}. Best is trial 10 with value: 114.95615419719232.\n",
      "[I 2023-12-06 19:37:40,991] Trial 11 finished with value: 98.65953239309094 and parameters: {'alpha': 0.3705111596010333}. Best is trial 11 with value: 98.65953239309094.\n",
      "[I 2023-12-06 19:49:06,605] Trial 12 finished with value: 95.25917518222703 and parameters: {'alpha': 0.23891867853433268}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:49:56,691] Trial 13 finished with value: 109.26933089821985 and parameters: {'alpha': 1.2990713084650842}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:50:14,057] Trial 14 finished with value: 115.34238763604091 and parameters: {'alpha': 10.109281221406519}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:50:31,281] Trial 15 finished with value: 115.36976777411624 and parameters: {'alpha': 13.698282775348147}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:51:22,469] Trial 16 finished with value: 108.93516278896296 and parameters: {'alpha': 1.245018312504908}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:51:39,045] Trial 17 finished with value: 115.37869015304406 and parameters: {'alpha': 16.735409292111765}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:51:55,575] Trial 18 finished with value: 115.37869015304406 and parameters: {'alpha': 15.34995341412418}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:52:23,154] Trial 19 finished with value: 115.14424854798224 and parameters: {'alpha': 7.807454048010346}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:52:39,729] Trial 20 finished with value: 115.37869015304406 and parameters: {'alpha': 18.873815956241103}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:54:11,687] Trial 21 finished with value: 107.34387026230891 and parameters: {'alpha': 1.0036363923295781}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:55:53,075] Trial 22 finished with value: 104.65956444243345 and parameters: {'alpha': 0.7030523994724605}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:56:20,408] Trial 23 finished with value: 115.29173149132389 and parameters: {'alpha': 9.57320973551697}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 19:56:47,899] Trial 24 finished with value: 115.27613194838747 and parameters: {'alpha': 9.40996853115698}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:10:53,344] Trial 25 finished with value: 96.14941609816326 and parameters: {'alpha': 0.271333303041267}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:11:17,163] Trial 26 finished with value: 115.37869015304406 and parameters: {'alpha': 22.1118253702775}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:11:41,735] Trial 27 finished with value: 115.36852630743799 and parameters: {'alpha': 13.549812763848776}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:12:05,017] Trial 28 finished with value: 115.37869015304406 and parameters: {'alpha': 23.46878030713198}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:12:29,732] Trial 29 finished with value: 115.37869015304406 and parameters: {'alpha': 20.032954077277775}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:13:13,307] Trial 30 finished with value: 115.19470225345431 and parameters: {'alpha': 8.47743069145121}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:14:11,240] Trial 31 finished with value: 113.75065250290365 and parameters: {'alpha': 2.0898690394652304}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:15:18,134] Trial 32 finished with value: 112.59172125024345 and parameters: {'alpha': 1.8215062077075714}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:22:25,720] Trial 33 finished with value: 100.23777931281741 and parameters: {'alpha': 0.4473551846878374}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:22:50,405] Trial 34 finished with value: 115.36849761000398 and parameters: {'alpha': 13.546367435503647}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:23:32,442] Trial 35 finished with value: 115.10776697499219 and parameters: {'alpha': 7.255951129524685}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:23:55,672] Trial 36 finished with value: 115.37869015304406 and parameters: {'alpha': 16.05833084153765}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:24:45,535] Trial 37 finished with value: 114.97987397702676 and parameters: {'alpha': 5.922096826222304}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:25:09,042] Trial 38 finished with value: 115.37869015304406 and parameters: {'alpha': 24.711589301161226}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:25:32,324] Trial 39 finished with value: 115.37869015304406 and parameters: {'alpha': 44.78749785228939}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:25:54,897] Trial 40 finished with value: 115.37869015304406 and parameters: {'alpha': 26.833559267481633}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:31:27,318] Trial 41 finished with value: 100.82142011829475 and parameters: {'alpha': 0.4784535651217159}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:32:15,968] Trial 42 finished with value: 114.92896781081012 and parameters: {'alpha': 5.595673415362533}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:32:40,064] Trial 43 finished with value: 115.3528588150837 and parameters: {'alpha': 11.56862128520719}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:33:32,599] Trial 44 finished with value: 114.78768868076278 and parameters: {'alpha': 4.902730225606213}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:41:14,464] Trial 45 finished with value: 98.77137993575592 and parameters: {'alpha': 0.3751773940825449}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:41:34,812] Trial 46 finished with value: 115.37869015304406 and parameters: {'alpha': 17.580533384927342}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:41:55,193] Trial 47 finished with value: 115.3544917958557 and parameters: {'alpha': 11.785418365616955}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:42:43,847] Trial 48 finished with value: 114.96691326738082 and parameters: {'alpha': 5.841266593705544}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:43:22,718] Trial 49 finished with value: 114.6771231478444 and parameters: {'alpha': 4.351062281796466}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:43:40,657] Trial 50 finished with value: 115.35003351743937 and parameters: {'alpha': 11.187074553258228}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:47:42,082] Trial 51 finished with value: 102.319268685686 and parameters: {'alpha': 0.5632817772937699}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:48:24,627] Trial 52 finished with value: 114.69556500805143 and parameters: {'alpha': 4.448513258023853}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:57:20,226] Trial 53 finished with value: 98.96503531714015 and parameters: {'alpha': 0.38326547079677975}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:57:53,703] Trial 54 finished with value: 115.21617406002756 and parameters: {'alpha': 8.738372978842937}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:58:11,021] Trial 55 finished with value: 115.37869015304406 and parameters: {'alpha': 14.743712590252843}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:58:55,330] Trial 56 finished with value: 114.57027212925671 and parameters: {'alpha': 3.8227659162161665}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 20:59:27,416] Trial 57 finished with value: 115.20954845732521 and parameters: {'alpha': 8.659164924851346}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:12:11,400] Trial 58 finished with value: 97.01728469111178 and parameters: {'alpha': 0.3038267078848603}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:12:28,429] Trial 59 finished with value: 115.37869015304406 and parameters: {'alpha': 17.375475386840428}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:13:11,946] Trial 60 finished with value: 114.85015970617067 and parameters: {'alpha': 5.185462717867134}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:13:59,025] Trial 61 finished with value: 114.41546631747667 and parameters: {'alpha': 2.907287816034029}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:29:14,541] Trial 62 finished with value: 95.80418018558099 and parameters: {'alpha': 0.2590586878784352}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:29:32,782] Trial 63 finished with value: 115.35070152285284 and parameters: {'alpha': 11.278046764322383}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:30:07,268] Trial 64 finished with value: 115.1478824877518 and parameters: {'alpha': 7.858875713818755}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:33:56,311] Trial 65 finished with value: 103.15190419410801 and parameters: {'alpha': 0.6133660061737842}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:34:41,889] Trial 66 finished with value: 114.61924068196524 and parameters: {'alpha': 4.064438324013045}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:34:58,043] Trial 67 finished with value: 115.37869015304406 and parameters: {'alpha': 20.384670247993917}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:35:31,248] Trial 68 finished with value: 115.23825468579871 and parameters: {'alpha': 8.994638433919981}. Best is trial 12 with value: 95.25917518222703.\n",
      "[I 2023-12-06 21:35:49,381] Trial 69 finished with value: 115.37727845205657 and parameters: {'alpha': 14.573672004703804}. Best is trial 12 with value: 95.25917518222703.\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+04, tolerance: 7.296e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+04, tolerance: 7.296e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+04, tolerance: 7.296e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+04, tolerance: 7.296e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+04, tolerance: 7.296e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2023-12-06 21:56:05,488] Trial 70 finished with value: 93.42249740578299 and parameters: {'alpha': 0.17463008747492775}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:04:22,431] Trial 71 finished with value: 99.26662125296416 and parameters: {'alpha': 0.39625650204255686}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:05:12,196] Trial 72 finished with value: 114.47237061502133 and parameters: {'alpha': 3.277227547614835}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:05:51,262] Trial 73 finished with value: 115.16275960000573 and parameters: {'alpha': 8.06381898551201}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:06:43,182] Trial 74 finished with value: 114.43465429685662 and parameters: {'alpha': 3.0362671454934897}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:07:27,072] Trial 75 finished with value: 115.0375648879838 and parameters: {'alpha': 6.27827582476528}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:07:46,503] Trial 76 finished with value: 115.36176074098566 and parameters: {'alpha': 12.720024493986749}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:08:41,351] Trial 77 finished with value: 114.37733053703558 and parameters: {'alpha': 2.68295975511514}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:22:13,272] Trial 78 finished with value: 95.98007504186404 and parameters: {'alpha': 0.2653750445602612}. Best is trial 70 with value: 93.42249740578299.\n",
      "[I 2023-12-06 22:22:30,199] Trial 79 finished with value: 115.34519077569125 and parameters: {'alpha': 10.512590390948862}. Best is trial 70 with value: 93.42249740578299.\n",
      "[W 2023-12-06 22:22:43,150] Trial 80 failed with parameters: {'alpha': 6.334090488967639} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_21572\\63415447.py\", line 24, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 905, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-06 22:22:43,202] Trial 80 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive - Universidad de los andes\\Doctorado\\Statistical learning\\Proyecto\\Proyecto SL PCA.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Configura y ejecuta el estudio de Optuna\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Minimizar el MSE\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(objective, n_trials\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)  \u001b[39m# Realiza 100 iteraciones (puedes ajustar este número)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Obtiene los mejores hiperparámetros y el mejor modelo\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[39m=\u001b[39m\u001b[39mtuple\u001b[39m(catch) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(catch, Iterable) \u001b[39melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive - Universidad de los andes\\Doctorado\\Statistical learning\\Proyecto\\Proyecto SL PCA.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):  \u001b[39m# K-fold cross-validation (5-fold en este ejemplo)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     X_train, X_valid, y_train, y_valid \u001b[39m=\u001b[39m train_test_split(X_pca, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_valid)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive%20-%20Universidad%20de%20los%20andes/Doctorado/Statistical%20learning/Proyecto/Proyecto%20SL%20PCA.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     mse \u001b[39m=\u001b[39m mean_squared_error(y_valid, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:905\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m    904\u001b[0m     X_copied \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_X \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept\n\u001b[1;32m--> 905\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    906\u001b[0m         X,\n\u001b[0;32m    907\u001b[0m         y,\n\u001b[0;32m    908\u001b[0m         accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    909\u001b[0m         order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    910\u001b[0m         dtype\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32],\n\u001b[0;32m    911\u001b[0m         copy\u001b[39m=\u001b[39mX_copied,\n\u001b[0;32m    912\u001b[0m         multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    913\u001b[0m         y_numeric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    914\u001b[0m     )\n\u001b[0;32m    915\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    916\u001b[0m         y, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    919\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[39m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[39m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[39m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[39m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[39m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype, xp\u001b[39m=\u001b[39mxp)\n\u001b[0;32m    918\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = data['V1']\n",
    "\n",
    "# Define la función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.1, 1e2)  # Hiperparámetro alpha (regularización)\n",
    "    # Crear el modelo de regresión polinomial con Lasso\n",
    "    model = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2)),  # Grado del polinomio\n",
    "        ('lasso', Lasso(alpha=alpha))  # Modelo Lasso\n",
    "    ])\n",
    "\n",
    "    # Entrenar y evaluar el modelo utilizando validación cruzada\n",
    "    mse_scores = []\n",
    "    for _ in range(5):  # K-fold cross-validation (5-fold en este ejemplo)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_valid)\n",
    "        mse = mean_squared_error(y_valid, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    # Devolver el error cuadrático medio promedio\n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "# Configura y ejecuta el estudio de Optuna\n",
    "study = optuna.create_study(direction='minimize')  # Minimizar el MSE\n",
    "study.optimize(objective, n_trials=100)  # Realiza 100 iteraciones (puedes ajustar este número)\n",
    "\n",
    "# Obtiene los mejores hiperparámetros y el mejor modelo\n",
    "best_params = study.best_params\n",
    "best_alpha = best_params['alpha']\n",
    "best_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('lasso', Lasso(alpha=best_alpha))\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
