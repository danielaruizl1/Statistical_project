{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6zQSEFpoY4z"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import optuna\n",
        "import joblib\n",
        "\n",
        "# Read data\n",
        "data = pd.read_excel('TrainClass.xlsx')\n",
        "real_data = pd.read_excel('TestClass.xlsx')\n",
        "\n",
        "# Prepare training data\n",
        "Y, X = data['FRACASO'], data.drop(['FRACASO', 'CODIGO_EMPRESA'], axis=1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Prepare testing data\n",
        "X = real_data.drop(['CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Define the objective function for BaggingClassifier with GradientBoostingClassifier\n",
        "def bagging_gb_objective(trial):\n",
        "    # Define hyperparameters for GradientBoostingClassifier\n",
        "    gb_n_estimators = trial.suggest_int('gb_n_estimators', 50, 200)\n",
        "    gb_max_depth = trial.suggest_int('gb_max_depth', 1, 10)\n",
        "\n",
        "    # Define hyperparameters for BaggingClassifier\n",
        "    bagging_n_estimators = trial.suggest_int('bagging_n_estimators', 10, 100)\n",
        "    bagging_max_samples = trial.suggest_float('bagging_max_samples', 0.1, 1.0)\n",
        "\n",
        "    # Create the base classifier with suggested hyperparameters\n",
        "    base_classifier = GradientBoostingClassifier(\n",
        "        n_estimators=gb_n_estimators,\n",
        "        max_depth=gb_max_depth,\n",
        "        random_state=0\n",
        "    )\n",
        "\n",
        "    # Create the bagging classifier with the base classifier\n",
        "    bagging_classifier = BaggingClassifier(\n",
        "        base_classifier,\n",
        "        n_estimators=bagging_n_estimators,\n",
        "        max_samples=bagging_max_samples,\n",
        "        random_state=0\n",
        "    )\n",
        "\n",
        "    # Define cross-validation strategy (StratifiedKFold for classification)\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "    # Perform cross-validation and get mean AUC\n",
        "    auc_scores = cross_val_score(bagging_classifier, X_train, Y_train, cv=cv, scoring='roc_auc')\n",
        "    mean_auc = auc_scores.mean()\n",
        "\n",
        "    return mean_auc\n",
        "\n",
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(bagging_gb_objective, n_trials=100)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "print(f'Best Hyperparameters for BaggingClassifier + GradientBoostingClassifier: {best_params}')\n",
        "\n",
        "# Create the base classifier with the best hyperparameters for GradientBoostingClassifier\n",
        "gb_classifier = GradientBoostingClassifier(\n",
        "    n_estimators=best_params['gb_n_estimators'],\n",
        "    max_depth=best_params['gb_max_depth'],\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# Create the bagging classifier with the best hyperparameters\n",
        "bagging_classifier = BaggingClassifier(\n",
        "    gb_classifier,\n",
        "    n_estimators=best_params['bagging_n_estimators'],\n",
        "    max_samples=best_params['bagging_max_samples'],\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# Train the bagging classifier\n",
        "bagging_classifier.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions on training set\n",
        "y_pred_train = bagging_classifier.predict(X_train)\n",
        "\n",
        "# Calculate AUC for training set\n",
        "auc_train = roc_auc_score(Y_train, y_pred_train)\n",
        "print(f'AUC for Training Set: {auc_train:.4f}')\n",
        "\n",
        "# Predictions on testing set\n",
        "y_pred_test = bagging_classifier.predict(X_test)\n",
        "\n",
        "# Calculate AUC for testing set\n",
        "auc_test = roc_auc_score(Y_test, y_pred_test)\n",
        "print(f'AUC for Testing Set: {auc_test:.4f}')\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(bagging_classifier, 'bagging_gb_model.joblib')\n",
        "\n",
        "# Load model and generate probability CSV\n",
        "loaded_model = joblib.load('bagging_gb_model.joblib')\n",
        "prob = loaded_model.predict_proba(X)[:, 1]\n",
        "prob_df = pd.DataFrame(prob, columns=['Probability'])\n",
        "prob_df.index = prob_df.index + 1\n",
        "prob_df.index.name = 'Id'\n",
        "prob_df.to_csv('intento.csv', index=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt3N8fKwogrM",
        "outputId": "9bc8610e-150f-4130-e288-b4f64fcf899b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-05 15:39:25,390] A new study created in memory with name: no-name-90610055-4ea8-4ca4-8451-ee20ff08798c\n",
            "[I 2023-12-05 15:44:43,424] Trial 0 finished with value: 0.7902285902503294 and parameters: {'gb_n_estimators': 171, 'gb_max_depth': 9, 'bagging_n_estimators': 17, 'bagging_max_samples': 0.6682231118470534}. Best is trial 0 with value: 0.7902285902503294.\n",
            "[I 2023-12-05 15:46:08,914] Trial 1 finished with value: 0.8338201581027669 and parameters: {'gb_n_estimators': 187, 'gb_max_depth': 3, 'bagging_n_estimators': 12, 'bagging_max_samples': 0.4989312535225958}. Best is trial 1 with value: 0.8338201581027669.\n",
            "[I 2023-12-05 15:52:07,993] Trial 2 finished with value: 0.8273776899429073 and parameters: {'gb_n_estimators': 185, 'gb_max_depth': 4, 'bagging_n_estimators': 35, 'bagging_max_samples': 0.608598170164457}. Best is trial 1 with value: 0.8338201581027669.\n",
            "[I 2023-12-05 16:13:09,231] Trial 3 finished with value: 0.8287110232762405 and parameters: {'gb_n_estimators': 141, 'gb_max_depth': 9, 'bagging_n_estimators': 98, 'bagging_max_samples': 0.5340479376672882}. Best is trial 1 with value: 0.8338201581027669.\n",
            "[I 2023-12-05 16:14:29,074] Trial 4 finished with value: 0.851512187088274 and parameters: {'gb_n_estimators': 77, 'gb_max_depth': 1, 'bagging_n_estimators': 72, 'bagging_max_samples': 0.4449636088910015}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:19:31,173] Trial 5 finished with value: 0.8262975406236276 and parameters: {'gb_n_estimators': 90, 'gb_max_depth': 5, 'bagging_n_estimators': 55, 'bagging_max_samples': 0.5281165502391632}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:24:39,775] Trial 6 finished with value: 0.8323629776021081 and parameters: {'gb_n_estimators': 138, 'gb_max_depth': 4, 'bagging_n_estimators': 37, 'bagging_max_samples': 0.6982583739548217}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:28:00,424] Trial 7 finished with value: 0.8258700043917434 and parameters: {'gb_n_estimators': 55, 'gb_max_depth': 7, 'bagging_n_estimators': 54, 'bagging_max_samples': 0.4375119985099153}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:42:04,448] Trial 8 finished with value: 0.8268376152832675 and parameters: {'gb_n_estimators': 150, 'gb_max_depth': 10, 'bagging_n_estimators': 98, 'bagging_max_samples': 0.35992569544702036}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:53:07,302] Trial 9 finished with value: 0.811453667105841 and parameters: {'gb_n_estimators': 144, 'gb_max_depth': 8, 'bagging_n_estimators': 72, 'bagging_max_samples': 0.4043666818281789}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:54:18,873] Trial 10 finished with value: 0.8484227053140095 and parameters: {'gb_n_estimators': 98, 'gb_max_depth': 1, 'bagging_n_estimators': 79, 'bagging_max_samples': 0.20552709916377657}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:55:11,087] Trial 11 finished with value: 0.8474249011857709 and parameters: {'gb_n_estimators': 90, 'gb_max_depth': 1, 'bagging_n_estimators': 76, 'bagging_max_samples': 0.143211466593898}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:56:21,949] Trial 12 finished with value: 0.8470454545454545 and parameters: {'gb_n_estimators': 99, 'gb_max_depth': 1, 'bagging_n_estimators': 76, 'bagging_max_samples': 0.22474339791213024}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 16:59:07,663] Trial 13 finished with value: 0.837677316644708 and parameters: {'gb_n_estimators': 52, 'gb_max_depth': 2, 'bagging_n_estimators': 85, 'bagging_max_samples': 0.8629704493504495}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:01:10,101] Trial 14 finished with value: 0.8449797979797979 and parameters: {'gb_n_estimators': 111, 'gb_max_depth': 2, 'bagging_n_estimators': 65, 'bagging_max_samples': 0.268993266173404}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:03:05,580] Trial 15 finished with value: 0.8259345630215196 and parameters: {'gb_n_estimators': 76, 'gb_max_depth': 6, 'bagging_n_estimators': 88, 'bagging_max_samples': 0.14841470942404394}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:04:58,030] Trial 16 finished with value: 0.8341407553798857 and parameters: {'gb_n_estimators': 72, 'gb_max_depth': 3, 'bagging_n_estimators': 61, 'bagging_max_samples': 0.2992926686555216}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:06:04,531] Trial 17 finished with value: 0.8498473869126043 and parameters: {'gb_n_estimators': 118, 'gb_max_depth': 1, 'bagging_n_estimators': 47, 'bagging_max_samples': 0.34024248949630537}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:08:39,655] Trial 18 finished with value: 0.8399165568730785 and parameters: {'gb_n_estimators': 118, 'gb_max_depth': 3, 'bagging_n_estimators': 47, 'bagging_max_samples': 0.33946482660933064}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:09:26,651] Trial 19 finished with value: 0.848590689503733 and parameters: {'gb_n_estimators': 71, 'gb_max_depth': 2, 'bagging_n_estimators': 28, 'bagging_max_samples': 0.42543649753429236}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:12:58,987] Trial 20 finished with value: 0.8273451910408431 and parameters: {'gb_n_estimators': 126, 'gb_max_depth': 5, 'bagging_n_estimators': 43, 'bagging_max_samples': 0.3121206385531511}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:13:43,880] Trial 21 finished with value: 0.8486220904699164 and parameters: {'gb_n_estimators': 74, 'gb_max_depth': 2, 'bagging_n_estimators': 24, 'bagging_max_samples': 0.4647737662690218}. Best is trial 4 with value: 0.851512187088274.\n",
            "[I 2023-12-05 17:14:11,070] Trial 22 finished with value: 0.8534757356170399 and parameters: {'gb_n_estimators': 81, 'gb_max_depth': 1, 'bagging_n_estimators': 23, 'bagging_max_samples': 0.4581240773380132}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:14:50,681] Trial 23 finished with value: 0.8498902064119456 and parameters: {'gb_n_estimators': 106, 'gb_max_depth': 1, 'bagging_n_estimators': 28, 'bagging_max_samples': 0.4163136295220542}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:15:18,523] Trial 24 finished with value: 0.8515603864734299 and parameters: {'gb_n_estimators': 87, 'gb_max_depth': 1, 'bagging_n_estimators': 23, 'bagging_max_samples': 0.41479609706977216}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:16:07,259] Trial 25 finished with value: 0.8386425120772948 and parameters: {'gb_n_estimators': 61, 'gb_max_depth': 3, 'bagging_n_estimators': 19, 'bagging_max_samples': 0.5918456928219745}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:16:49,732] Trial 26 finished with value: 0.8221183574879227 and parameters: {'gb_n_estimators': 84, 'gb_max_depth': 4, 'bagging_n_estimators': 11, 'bagging_max_samples': 0.47648531128781385}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:17:39,567] Trial 27 finished with value: 0.8424503732981993 and parameters: {'gb_n_estimators': 65, 'gb_max_depth': 2, 'bagging_n_estimators': 35, 'bagging_max_samples': 0.3821512287300996}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:19:11,842] Trial 28 finished with value: 0.844943456302152 and parameters: {'gb_n_estimators': 84, 'gb_max_depth': 1, 'bagging_n_estimators': 68, 'bagging_max_samples': 0.5672388311651954}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:23:21,229] Trial 29 finished with value: 0.8130904699165569 and parameters: {'gb_n_estimators': 158, 'gb_max_depth': 6, 'bagging_n_estimators': 19, 'bagging_max_samples': 0.6552241838342041}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:25:44,499] Trial 30 finished with value: 0.8419580588493633 and parameters: {'gb_n_estimators': 101, 'gb_max_depth': 2, 'bagging_n_estimators': 57, 'bagging_max_samples': 0.46181531683036303}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:26:22,286] Trial 31 finished with value: 0.8499903381642513 and parameters: {'gb_n_estimators': 108, 'gb_max_depth': 1, 'bagging_n_estimators': 27, 'bagging_max_samples': 0.40131564634468336}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:26:52,903] Trial 32 finished with value: 0.8501729249011858 and parameters: {'gb_n_estimators': 84, 'gb_max_depth': 1, 'bagging_n_estimators': 24, 'bagging_max_samples': 0.4962401771804117}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:27:36,250] Trial 33 finished with value: 0.836923583662714 and parameters: {'gb_n_estimators': 84, 'gb_max_depth': 3, 'bagging_n_estimators': 14, 'bagging_max_samples': 0.49078685482085127}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:28:13,136] Trial 34 finished with value: 0.8416525032938076 and parameters: {'gb_n_estimators': 62, 'gb_max_depth': 2, 'bagging_n_estimators': 22, 'bagging_max_samples': 0.52552040037172}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:34:01,896] Trial 35 finished with value: 0.8302202459376373 and parameters: {'gb_n_estimators': 197, 'gb_max_depth': 4, 'bagging_n_estimators': 35, 'bagging_max_samples': 0.539465907060265}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:35:46,258] Trial 36 finished with value: 0.8401113306982871 and parameters: {'gb_n_estimators': 90, 'gb_max_depth': 3, 'bagging_n_estimators': 31, 'bagging_max_samples': 0.50309133518227}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:36:42,307] Trial 37 finished with value: 0.8517332015810277 and parameters: {'gb_n_estimators': 79, 'gb_max_depth': 1, 'bagging_n_estimators': 41, 'bagging_max_samples': 0.6191469117527317}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:38:20,771] Trial 38 finished with value: 0.8429055775142731 and parameters: {'gb_n_estimators': 78, 'gb_max_depth': 2, 'bagging_n_estimators': 41, 'bagging_max_samples': 0.6357492959238045}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:43:36,313] Trial 39 finished with value: 0.816723759332455 and parameters: {'gb_n_estimators': 56, 'gb_max_depth': 8, 'bagging_n_estimators': 51, 'bagging_max_samples': 0.7059235046085295}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:45:15,225] Trial 40 finished with value: 0.8147184892402285 and parameters: {'gb_n_estimators': 94, 'gb_max_depth': 5, 'bagging_n_estimators': 16, 'bagging_max_samples': 0.5855915842369276}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:45:36,337] Trial 41 finished with value: 0.8427139877031182 and parameters: {'gb_n_estimators': 65, 'gb_max_depth': 1, 'bagging_n_estimators': 22, 'bagging_max_samples': 0.4390729868637578}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:46:30,182] Trial 42 finished with value: 0.8476970794905577 and parameters: {'gb_n_estimators': 83, 'gb_max_depth': 1, 'bagging_n_estimators': 42, 'bagging_max_samples': 0.5220326898169886}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:46:57,488] Trial 43 finished with value: 0.8507165129556433 and parameters: {'gb_n_estimators': 67, 'gb_max_depth': 1, 'bagging_n_estimators': 32, 'bagging_max_samples': 0.361540607626766}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:47:46,066] Trial 44 finished with value: 0.8441881862099254 and parameters: {'gb_n_estimators': 69, 'gb_max_depth': 2, 'bagging_n_estimators': 33, 'bagging_max_samples': 0.37243378703811264}. Best is trial 22 with value: 0.8534757356170399.\n",
            "[I 2023-12-05 17:48:11,576] Trial 45 finished with value: 0.8543986605182259 and parameters: {'gb_n_estimators': 53, 'gb_max_depth': 1, 'bagging_n_estimators': 38, 'bagging_max_samples': 0.3864688941825}. Best is trial 45 with value: 0.8543986605182259.\n",
            "[I 2023-12-05 17:48:42,442] Trial 46 finished with value: 0.8548416776460256 and parameters: {'gb_n_estimators': 57, 'gb_max_depth': 1, 'bagging_n_estimators': 38, 'bagging_max_samples': 0.44524545276643496}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 17:49:30,989] Trial 47 finished with value: 0.8455799297321036 and parameters: {'gb_n_estimators': 54, 'gb_max_depth': 2, 'bagging_n_estimators': 40, 'bagging_max_samples': 0.39740201997346014}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 17:52:14,034] Trial 48 finished with value: 0.8073388230127361 and parameters: {'gb_n_estimators': 58, 'gb_max_depth': 10, 'bagging_n_estimators': 37, 'bagging_max_samples': 0.44671159885516454}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 17:52:52,604] Trial 49 finished with value: 0.8506991655687308 and parameters: {'gb_n_estimators': 50, 'gb_max_depth': 1, 'bagging_n_estimators': 47, 'bagging_max_samples': 0.5444467694808173}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 17:58:57,681] Trial 50 finished with value: 0.8325531400966184 and parameters: {'gb_n_estimators': 168, 'gb_max_depth': 3, 'bagging_n_estimators': 51, 'bagging_max_samples': 0.6105151715967877}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:00:36,366] Trial 51 finished with value: 0.8516976284584981 and parameters: {'gb_n_estimators': 78, 'gb_max_depth': 1, 'bagging_n_estimators': 90, 'bagging_max_samples': 0.4350115565079727}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:02:41,616] Trial 52 finished with value: 0.8515430390865173 and parameters: {'gb_n_estimators': 92, 'gb_max_depth': 1, 'bagging_n_estimators': 100, 'bagging_max_samples': 0.4205802977101895}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:04:27,527] Trial 53 finished with value: 0.8483684672815107 and parameters: {'gb_n_estimators': 77, 'gb_max_depth': 1, 'bagging_n_estimators': 93, 'bagging_max_samples': 0.4737072339351005}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:05:04,127] Trial 54 finished with value: 0.8417360562143171 and parameters: {'gb_n_estimators': 50, 'gb_max_depth': 2, 'bagging_n_estimators': 39, 'bagging_max_samples': 0.3138648061630371}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:06:41,515] Trial 55 finished with value: 0.8459743083003952 and parameters: {'gb_n_estimators': 133, 'gb_max_depth': 1, 'bagging_n_estimators': 59, 'bagging_max_samples': 0.3617772284171914}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:08:06,668] Trial 56 finished with value: 0.8450096618357488 and parameters: {'gb_n_estimators': 79, 'gb_max_depth': 2, 'bagging_n_estimators': 45, 'bagging_max_samples': 0.434442906916076}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:08:37,691] Trial 57 finished with value: 0.8537786561264822 and parameters: {'gb_n_estimators': 58, 'gb_max_depth': 1, 'bagging_n_estimators': 51, 'bagging_max_samples': 0.26389425853636045}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:09:33,385] Trial 58 finished with value: 0.8429227053140096 and parameters: {'gb_n_estimators': 62, 'gb_max_depth': 2, 'bagging_n_estimators': 51, 'bagging_max_samples': 0.2778787608070694}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:11:16,642] Trial 59 finished with value: 0.8111543697848045 and parameters: {'gb_n_estimators': 57, 'gb_max_depth': 8, 'bagging_n_estimators': 63, 'bagging_max_samples': 0.21692452585682254}. Best is trial 46 with value: 0.8548416776460256.\n",
            "[I 2023-12-05 18:11:57,788] Trial 60 finished with value: 0.8556545893719807 and parameters: {'gb_n_estimators': 72, 'gb_max_depth': 1, 'bagging_n_estimators': 55, 'bagging_max_samples': 0.2484856998794715}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:12:36,950] Trial 61 finished with value: 0.8548978919631093 and parameters: {'gb_n_estimators': 72, 'gb_max_depth': 1, 'bagging_n_estimators': 55, 'bagging_max_samples': 0.24747552697816125}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:13:16,107] Trial 62 finished with value: 0.8529279754062362 and parameters: {'gb_n_estimators': 71, 'gb_max_depth': 1, 'bagging_n_estimators': 53, 'bagging_max_samples': 0.24835457787109813}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:13:54,203] Trial 63 finished with value: 0.8538197189284146 and parameters: {'gb_n_estimators': 68, 'gb_max_depth': 1, 'bagging_n_estimators': 56, 'bagging_max_samples': 0.24869898623074937}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:14:42,399] Trial 64 finished with value: 0.8394049187527448 and parameters: {'gb_n_estimators': 59, 'gb_max_depth': 2, 'bagging_n_estimators': 68, 'bagging_max_samples': 0.1605397576046304}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:15:30,400] Trial 65 finished with value: 0.8415790513833992 and parameters: {'gb_n_estimators': 66, 'gb_max_depth': 2, 'bagging_n_estimators': 57, 'bagging_max_samples': 0.17592032748674585}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:16:16,116] Trial 66 finished with value: 0.8528210364514713 and parameters: {'gb_n_estimators': 72, 'gb_max_depth': 1, 'bagging_n_estimators': 61, 'bagging_max_samples': 0.25701554915245517}. Best is trial 60 with value: 0.8556545893719807.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1 fits failed out of a total of 5.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\", line 337, in fit\n",
            "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\", line 472, in _fit\n",
            "    all_results = Parallel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1863, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\", line 141, in _parallel_build_estimators\n",
            "    estimator_fit(X_, y, sample_weight=curr_sample_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 440, in fit\n",
            "    y = self._validate_y(y, sample_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 1232, in _validate_y\n",
            "    raise ValueError(\n",
            "ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "[W 2023-12-05 18:16:34,583] Trial 67 failed with parameters: {'gb_n_estimators': 54, 'gb_max_depth': 1, 'bagging_n_estimators': 54, 'bagging_max_samples': 0.10936960725997905} because of the following error: The value nan is not acceptable.\n",
            "[W 2023-12-05 18:16:34,584] Trial 67 failed with value nan.\n",
            "[I 2023-12-05 18:17:00,695] Trial 68 finished with value: 0.8540816864295128 and parameters: {'gb_n_estimators': 53, 'gb_max_depth': 1, 'bagging_n_estimators': 55, 'bagging_max_samples': 0.1971158518606662}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:17:54,398] Trial 69 finished with value: 0.8373818620992534 and parameters: {'gb_n_estimators': 54, 'gb_max_depth': 3, 'bagging_n_estimators': 55, 'bagging_max_samples': 0.19342704099358504}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:19:51,964] Trial 70 finished with value: 0.8135189942907335 and parameters: {'gb_n_estimators': 62, 'gb_max_depth': 9, 'bagging_n_estimators': 67, 'bagging_max_samples': 0.2149275929378624}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:20:16,622] Trial 71 finished with value: 0.851568730786122 and parameters: {'gb_n_estimators': 50, 'gb_max_depth': 2, 'bagging_n_estimators': 49, 'bagging_max_samples': 0.11139214948904605}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:20:55,898] Trial 72 finished with value: 0.8528258673693457 and parameters: {'gb_n_estimators': 65, 'gb_max_depth': 1, 'bagging_n_estimators': 57, 'bagging_max_samples': 0.28111655888490134}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:21:39,129] Trial 73 finished with value: 0.8545858585858586 and parameters: {'gb_n_estimators': 59, 'gb_max_depth': 1, 'bagging_n_estimators': 71, 'bagging_max_samples': 0.2491551815438567}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:22:23,305] Trial 74 finished with value: 0.8512692138779094 and parameters: {'gb_n_estimators': 55, 'gb_max_depth': 1, 'bagging_n_estimators': 81, 'bagging_max_samples': 0.2418696441882209}. Best is trial 60 with value: 0.8556545893719807.\n",
            "[I 2023-12-05 18:22:55,533] Trial 75 finished with value: 0.8557031181379008 and parameters: {'gb_n_estimators': 74, 'gb_max_depth': 1, 'bagging_n_estimators': 45, 'bagging_max_samples': 0.23087563374165687}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:23:48,635] Trial 76 finished with value: 0.852399429073342 and parameters: {'gb_n_estimators': 74, 'gb_max_depth': 2, 'bagging_n_estimators': 46, 'bagging_max_samples': 0.2348364853886531}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:24:27,798] Trial 77 finished with value: 0.8494042599912165 and parameters: {'gb_n_estimators': 61, 'gb_max_depth': 1, 'bagging_n_estimators': 73, 'bagging_max_samples': 0.1968707446051117}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:25:01,699] Trial 78 finished with value: 0.8478498023715415 and parameters: {'gb_n_estimators': 69, 'gb_max_depth': 1, 'bagging_n_estimators': 44, 'bagging_max_samples': 0.3008150744229037}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:26:32,602] Trial 79 finished with value: 0.8440043917435223 and parameters: {'gb_n_estimators': 74, 'gb_max_depth': 2, 'bagging_n_estimators': 62, 'bagging_max_samples': 0.32962419596097503}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:27:10,027] Trial 80 finished with value: 0.8527090469916556 and parameters: {'gb_n_estimators': 64, 'gb_max_depth': 1, 'bagging_n_estimators': 54, 'bagging_max_samples': 0.28685421453087084}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:28:15,687] Trial 81 finished with value: 0.8338998682476942 and parameters: {'gb_n_estimators': 69, 'gb_max_depth': 4, 'bagging_n_estimators': 37, 'bagging_max_samples': 0.23023201138662122}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:28:53,434] Trial 82 finished with value: 0.8517531840140535 and parameters: {'gb_n_estimators': 59, 'gb_max_depth': 1, 'bagging_n_estimators': 59, 'bagging_max_samples': 0.2632933908443557}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:31:02,385] Trial 83 finished with value: 0.8012694334650856 and parameters: {'gb_n_estimators': 53, 'gb_max_depth': 7, 'bagging_n_estimators': 49, 'bagging_max_samples': 0.3311793055261513}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:31:35,614] Trial 84 finished with value: 0.849554677206851 and parameters: {'gb_n_estimators': 58, 'gb_max_depth': 1, 'bagging_n_estimators': 64, 'bagging_max_samples': 0.19763359630562477}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:32:02,739] Trial 85 finished with value: 0.8532755819060165 and parameters: {'gb_n_estimators': 55, 'gb_max_depth': 1, 'bagging_n_estimators': 49, 'bagging_max_samples': 0.2591449772623535}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:33:04,945] Trial 86 finished with value: 0.839235617039965 and parameters: {'gb_n_estimators': 65, 'gb_max_depth': 2, 'bagging_n_estimators': 52, 'bagging_max_samples': 0.3015670756002085}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:33:30,612] Trial 87 finished with value: 0.855471892841458 and parameters: {'gb_n_estimators': 60, 'gb_max_depth': 1, 'bagging_n_estimators': 43, 'bagging_max_samples': 0.22346725611669357}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:33:55,930] Trial 88 finished with value: 0.8551554677206852 and parameters: {'gb_n_estimators': 70, 'gb_max_depth': 1, 'bagging_n_estimators': 39, 'bagging_max_samples': 0.22259618672661485}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:34:24,995] Trial 89 finished with value: 0.8508087395696091 and parameters: {'gb_n_estimators': 88, 'gb_max_depth': 1, 'bagging_n_estimators': 39, 'bagging_max_samples': 0.17732396306537646}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:34:57,970] Trial 90 finished with value: 0.8490491875274483 and parameters: {'gb_n_estimators': 74, 'gb_max_depth': 2, 'bagging_n_estimators': 30, 'bagging_max_samples': 0.22143897238668078}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:35:35,854] Trial 91 finished with value: 0.8468684672815108 and parameters: {'gb_n_estimators': 150, 'gb_max_depth': 1, 'bagging_n_estimators': 34, 'bagging_max_samples': 0.13363214059766768}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:36:01,656] Trial 92 finished with value: 0.85239898989899 and parameters: {'gb_n_estimators': 69, 'gb_max_depth': 1, 'bagging_n_estimators': 45, 'bagging_max_samples': 0.17708829812379914}. Best is trial 75 with value: 0.8557031181379008.\n",
            "[I 2023-12-05 18:36:29,206] Trial 93 finished with value: 0.8565911286780853 and parameters: {'gb_n_estimators': 62, 'gb_max_depth': 1, 'bagging_n_estimators': 43, 'bagging_max_samples': 0.2447437189300218}. Best is trial 93 with value: 0.8565911286780853.\n",
            "[I 2023-12-05 18:36:50,013] Trial 94 finished with value: 0.8547086078173034 and parameters: {'gb_n_estimators': 62, 'gb_max_depth': 1, 'bagging_n_estimators': 37, 'bagging_max_samples': 0.21048066598437523}. Best is trial 93 with value: 0.8565911286780853.\n",
            "[I 2023-12-05 18:37:18,612] Trial 95 finished with value: 0.8549444444444443 and parameters: {'gb_n_estimators': 60, 'gb_max_depth': 1, 'bagging_n_estimators': 43, 'bagging_max_samples': 0.2809710399983327}. Best is trial 93 with value: 0.8565911286780853.\n",
            "[I 2023-12-05 18:37:59,008] Trial 96 finished with value: 0.8497044356609574 and parameters: {'gb_n_estimators': 62, 'gb_max_depth': 2, 'bagging_n_estimators': 43, 'bagging_max_samples': 0.23325057153622922}. Best is trial 93 with value: 0.8565911286780853.\n",
            "[I 2023-12-05 18:38:37,424] Trial 97 finished with value: 0.8517591128678085 and parameters: {'gb_n_estimators': 80, 'gb_max_depth': 1, 'bagging_n_estimators': 43, 'bagging_max_samples': 0.2863944114536056}. Best is trial 93 with value: 0.8565911286780853.\n",
            "[I 2023-12-05 18:39:14,229] Trial 98 finished with value: 0.8475915678524375 and parameters: {'gb_n_estimators': 72, 'gb_max_depth': 2, 'bagging_n_estimators': 36, 'bagging_max_samples': 0.20978536973459894}. Best is trial 93 with value: 0.8565911286780853.\n",
            "[I 2023-12-05 18:39:47,128] Trial 99 finished with value: 0.8539795783926218 and parameters: {'gb_n_estimators': 76, 'gb_max_depth': 1, 'bagging_n_estimators': 40, 'bagging_max_samples': 0.2758210852208832}. Best is trial 93 with value: 0.8565911286780853.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters for BaggingClassifier + GradientBoostingClassifier: {'gb_n_estimators': 62, 'gb_max_depth': 1, 'bagging_n_estimators': 43, 'bagging_max_samples': 0.2447437189300218}\n",
            "AUC for Training Set: 0.6176\n",
            "AUC for Testing Set: 0.5440\n"
          ]
        }
      ]
    }
  ]
}