{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkj7N0y3mL5F",
        "outputId": "d2bab4de-f3ef-441d-b1b3-9107a52541d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.0-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.0 colorlog-6.8.0 optuna-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import optuna\n",
        "import joblib"
      ],
      "metadata": {
        "id": "MbvqOmBJmJUU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFvgdsFAk0iR",
        "outputId": "b00fa3e1-42a1-41a5-98de-45c8e0b443ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC for Training Set: 0.6073\n",
            "AUC for Testing Set: 0.5866\n"
          ]
        }
      ],
      "source": [
        "# Read data\n",
        "data = pd.read_excel('TrainClass.xlsx')\n",
        "real_data = pd.read_excel('TestClass.xlsx')\n",
        "\n",
        "# Prepare training data\n",
        "Y, X = data['FRACASO'], data.drop(['FRACASO', 'CODIGO_EMPRESA'], axis=1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Prepare testing data\n",
        "X = real_data.drop(['CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Best hyperparameters for RandomForestClassifier\n",
        "rf_best_params = {'n_estimators': 138, 'max_depth': 3}\n",
        "\n",
        "# Best hyperparameters for GradientBoostingClassifier\n",
        "gb_best_params = {'n_estimators': 178, 'learning_rate': 0.016627816667251865, 'max_depth': 4}\n",
        "\n",
        "# Create the base classifiers\n",
        "rf_classifier = RandomForestClassifier(**rf_best_params, random_state=0)\n",
        "gb_classifier = GradientBoostingClassifier(**gb_best_params, random_state=0)\n",
        "\n",
        "# Create the stacking classifier with the base classifiers\n",
        "stacking_classifier = StackingClassifier(\n",
        "    estimators=[('random_forest', rf_classifier), ('gradient_boosting', gb_classifier)],\n",
        "    final_estimator=RandomForestClassifier(random_state=0)  # You can choose a different final estimator if needed\n",
        ")\n",
        "\n",
        "# Train the stacking classifier\n",
        "stacking_classifier.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions on training set\n",
        "y_pred_train = stacking_classifier.predict(X_train)\n",
        "\n",
        "# Calculate AUC for training set\n",
        "auc_train = roc_auc_score(Y_train, y_pred_train)\n",
        "print(f'AUC for Training Set: {auc_train:.4f}')\n",
        "\n",
        "# Predictions on testing set\n",
        "y_pred_test = stacking_classifier.predict(X_test)\n",
        "\n",
        "# Calculate AUC for testing set\n",
        "auc_test = roc_auc_score(Y_test, y_pred_test)\n",
        "print(f'AUC for Testing Set: {auc_test:.4f}')\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(stacking_classifier, 'stacking_model.joblib')\n",
        "\n",
        "# Load model and generate probability CSV\n",
        "loaded_model = joblib.load('stacking_model.joblib')\n",
        "prob = loaded_model.predict_proba(X)[:, 1]\n",
        "prob_df = pd.DataFrame(prob, columns=['Probability'])\n",
        "prob_df.index = prob_df.index + 1\n",
        "prob_df.index.name = 'Id'\n",
        "prob_df.to_csv('intento.csv', index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "data = pd.read_excel('TrainClass.xlsx')\n",
        "real_data = pd.read_excel('TestClass.xlsx')\n",
        "\n",
        "# Prepare training data\n",
        "Y, X = data['FRACASO'], data.drop(['FRACASO', 'CODIGO_EMPRESA'], axis=1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Prepare testing data\n",
        "X = real_data.drop(['CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Define the objective function for StackingClassifier\n",
        "def stacking_objective(trial):\n",
        "    # Define hyperparameters for RandomForestClassifier\n",
        "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 50, 200)\n",
        "    rf_max_depth = trial.suggest_int('rf_max_depth', 1, 10)\n",
        "\n",
        "    # Define hyperparameters for GradientBoostingClassifier\n",
        "    gb_n_estimators = trial.suggest_int('gb_n_estimators', 50, 200)\n",
        "    gb_learning_rate = trial.suggest_float('gb_learning_rate', 0.001, 0.1)\n",
        "    gb_max_depth = trial.suggest_int('gb_max_depth', 1, 10)\n",
        "\n",
        "    # Create the base classifiers with suggested hyperparameters\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=rf_n_estimators, max_depth=rf_max_depth, random_state=0)\n",
        "    gb_classifier = GradientBoostingClassifier(n_estimators=gb_n_estimators, learning_rate=gb_learning_rate, max_depth=gb_max_depth, random_state=0)\n",
        "\n",
        "    # Create the stacking classifier with the base classifiers\n",
        "    stacking_classifier = StackingClassifier(\n",
        "        estimators=[('random_forest', rf_classifier), ('gradient_boosting', gb_classifier)],\n",
        "        final_estimator=RandomForestClassifier(random_state=0)  # You can choose a different final estimator if needed\n",
        "    )\n",
        "\n",
        "    # Define cross-validation strategy (StratifiedKFold for classification)\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "    # Perform cross-validation and get mean AUC\n",
        "    auc_scores = cross_val_score(stacking_classifier, X_train, Y_train, cv=cv, scoring='roc_auc')\n",
        "    mean_auc = auc_scores.mean()\n",
        "\n",
        "    return mean_auc\n",
        "\n",
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(stacking_objective, n_trials=100)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "print(f'Best Hyperparameters for StackingClassifier: {best_params}')\n",
        "\n",
        "# Create the stacking classifier with the best hyperparameters\n",
        "rf_classifier = RandomForestClassifier(n_estimators=best_params['rf_n_estimators'], max_depth=best_params['rf_max_depth'], random_state=0)\n",
        "gb_classifier = GradientBoostingClassifier(n_estimators=best_params['gb_n_estimators'], learning_rate=best_params['gb_learning_rate'], max_depth=best_params['gb_max_depth'], random_state=0)\n",
        "\n",
        "stacking_classifier = StackingClassifier(\n",
        "    estimators=[('random_forest', rf_classifier), ('gradient_boosting', gb_classifier)],\n",
        "    final_estimator=RandomForestClassifier(random_state=0)  # You can choose a different final estimator if needed\n",
        ")\n",
        "\n",
        "# Train the stacking classifier\n",
        "stacking_classifier.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions on training set\n",
        "y_pred_train = stacking_classifier.predict(X_train)\n",
        "\n",
        "# Calculate AUC for training set\n",
        "auc_train = roc_auc_score(Y_train, y_pred_train)\n",
        "print(f'AUC for Training Set: {auc_train:.4f}')\n",
        "\n",
        "# Predictions on testing set\n",
        "y_pred_test = stacking_classifier.predict(X_test)\n",
        "\n",
        "# Calculate AUC for testing set\n",
        "auc_test = roc_auc_score(Y_test, y_pred_test)\n",
        "print(f'AUC for Testing Set: {auc_test:.4f}')\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(stacking_classifier, 'stacking_model.joblib')\n",
        "\n",
        "# Load model and generate probability CSV\n",
        "loaded_model = joblib.load('stacking_model.joblib')\n",
        "prob = loaded_model.predict_proba(X)[:, 1]\n",
        "prob_df = pd.DataFrame(prob, columns=['Probability'])\n",
        "prob_df.index = prob_df.index + 1\n",
        "prob_df.index.name = 'Id'\n",
        "prob_df.to_csv('intento.csv', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxfgd81rmIBc",
        "outputId": "987967e3-5213-4f17-e29a-30c47cece47b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-05 15:31:39,359] A new study created in memory with name: no-name-f6994b8a-8d23-4ce0-b9db-4604d4f14bf2\n",
            "[I 2023-12-05 15:33:32,625] Trial 0 finished with value: 0.7897013614404917 and parameters: {'rf_n_estimators': 106, 'rf_max_depth': 4, 'gb_n_estimators': 165, 'gb_learning_rate': 0.08799250022732304, 'gb_max_depth': 4}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:34:50,408] Trial 1 finished with value: 0.7450110891523936 and parameters: {'rf_n_estimators': 160, 'rf_max_depth': 5, 'gb_n_estimators': 185, 'gb_learning_rate': 0.03956330584826514, 'gb_max_depth': 2}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:37:06,089] Trial 2 finished with value: 0.7733988801054019 and parameters: {'rf_n_estimators': 164, 'rf_max_depth': 3, 'gb_n_estimators': 141, 'gb_learning_rate': 0.0421620043113306, 'gb_max_depth': 6}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:38:18,896] Trial 3 finished with value: 0.7332183794466403 and parameters: {'rf_n_estimators': 72, 'rf_max_depth': 5, 'gb_n_estimators': 110, 'gb_learning_rate': 0.02919758631459337, 'gb_max_depth': 4}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:41:42,869] Trial 4 finished with value: 0.7285274483970137 and parameters: {'rf_n_estimators': 188, 'rf_max_depth': 6, 'gb_n_estimators': 148, 'gb_learning_rate': 0.07174685037243385, 'gb_max_depth': 9}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:43:35,623] Trial 5 finished with value: 0.734526460254721 and parameters: {'rf_n_estimators': 186, 'rf_max_depth': 8, 'gb_n_estimators': 115, 'gb_learning_rate': 0.05438603708571936, 'gb_max_depth': 5}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:44:29,251] Trial 6 finished with value: 0.774379117259552 and parameters: {'rf_n_estimators': 151, 'rf_max_depth': 6, 'gb_n_estimators': 189, 'gb_learning_rate': 0.04727566178848625, 'gb_max_depth': 1}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:46:46,396] Trial 7 finished with value: 0.7511115502854634 and parameters: {'rf_n_estimators': 101, 'rf_max_depth': 4, 'gb_n_estimators': 179, 'gb_learning_rate': 0.07993298535644237, 'gb_max_depth': 5}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:48:13,796] Trial 8 finished with value: 0.7426140755379885 and parameters: {'rf_n_estimators': 155, 'rf_max_depth': 4, 'gb_n_estimators': 158, 'gb_learning_rate': 0.05248394030234352, 'gb_max_depth': 3}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:51:03,569] Trial 9 finished with value: 0.6871901624945104 and parameters: {'rf_n_estimators': 113, 'rf_max_depth': 10, 'gb_n_estimators': 138, 'gb_learning_rate': 0.07122028920419302, 'gb_max_depth': 8}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:51:59,072] Trial 10 finished with value: 0.7142068511198946 and parameters: {'rf_n_estimators': 63, 'rf_max_depth': 1, 'gb_n_estimators': 52, 'gb_learning_rate': 0.09703776559711275, 'gb_max_depth': 7}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:52:52,515] Trial 11 finished with value: 0.7718466183574879 and parameters: {'rf_n_estimators': 129, 'rf_max_depth': 7, 'gb_n_estimators': 198, 'gb_learning_rate': 0.011381859485516725, 'gb_max_depth': 1}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:53:29,810] Trial 12 finished with value: 0.6600534694773825 and parameters: {'rf_n_estimators': 132, 'rf_max_depth': 2, 'gb_n_estimators': 163, 'gb_learning_rate': 0.09932395412923638, 'gb_max_depth': 1}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:55:14,132] Trial 13 finished with value: 0.7468876811594203 and parameters: {'rf_n_estimators': 89, 'rf_max_depth': 9, 'gb_n_estimators': 200, 'gb_learning_rate': 0.06097167170290477, 'gb_max_depth': 3}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 15:59:18,199] Trial 14 finished with value: 0.7854694773825209 and parameters: {'rf_n_estimators': 133, 'rf_max_depth': 7, 'gb_n_estimators': 174, 'gb_learning_rate': 0.08697148881938546, 'gb_max_depth': 10}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 16:01:23,936] Trial 15 finished with value: 0.7459001976284585 and parameters: {'rf_n_estimators': 84, 'rf_max_depth': 7, 'gb_n_estimators': 86, 'gb_learning_rate': 0.08713911632160563, 'gb_max_depth': 10}. Best is trial 0 with value: 0.7897013614404917.\n",
            "[I 2023-12-05 16:04:27,437] Trial 16 finished with value: 0.7998480456741326 and parameters: {'rf_n_estimators': 126, 'rf_max_depth': 8, 'gb_n_estimators': 171, 'gb_learning_rate': 0.08766405926162858, 'gb_max_depth': 7}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:06:51,463] Trial 17 finished with value: 0.7514614624505929 and parameters: {'rf_n_estimators': 111, 'rf_max_depth': 10, 'gb_n_estimators': 130, 'gb_learning_rate': 0.07020500546160915, 'gb_max_depth': 7}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:09:25,544] Trial 18 finished with value: 0.7498875713658323 and parameters: {'rf_n_estimators': 98, 'rf_max_depth': 8, 'gb_n_estimators': 165, 'gb_learning_rate': 0.08817804581845215, 'gb_max_depth': 6}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:10:26,304] Trial 19 finished with value: 0.7105138339920948 and parameters: {'rf_n_estimators': 54, 'rf_max_depth': 3, 'gb_n_estimators': 96, 'gb_learning_rate': 0.07751379623427974, 'gb_max_depth': 4}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:13:35,355] Trial 20 finished with value: 0.7029952788757136 and parameters: {'rf_n_estimators': 119, 'rf_max_depth': 9, 'gb_n_estimators': 156, 'gb_learning_rate': 0.06336019225537838, 'gb_max_depth': 8}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:17:41,295] Trial 21 finished with value: 0.7695631313131314 and parameters: {'rf_n_estimators': 140, 'rf_max_depth': 7, 'gb_n_estimators': 174, 'gb_learning_rate': 0.08537388174179959, 'gb_max_depth': 10}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:21:22,804] Trial 22 finished with value: 0.7827139877031183 and parameters: {'rf_n_estimators': 141, 'rf_max_depth': 8, 'gb_n_estimators': 171, 'gb_learning_rate': 0.09299734915578775, 'gb_max_depth': 9}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:24:11,766] Trial 23 finished with value: 0.6998534255599473 and parameters: {'rf_n_estimators': 175, 'rf_max_depth': 6, 'gb_n_estimators': 151, 'gb_learning_rate': 0.08166568108827536, 'gb_max_depth': 7}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:26:11,559] Trial 24 finished with value: 0.7510151515151515 and parameters: {'rf_n_estimators': 124, 'rf_max_depth': 4, 'gb_n_estimators': 186, 'gb_learning_rate': 0.09194484128782231, 'gb_max_depth': 4}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:29:08,358] Trial 25 finished with value: 0.7519692577953447 and parameters: {'rf_n_estimators': 142, 'rf_max_depth': 9, 'gb_n_estimators': 126, 'gb_learning_rate': 0.09773822837429184, 'gb_max_depth': 9}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:32:30,571] Trial 26 finished with value: 0.7903324549846289 and parameters: {'rf_n_estimators': 106, 'rf_max_depth': 7, 'gb_n_estimators': 173, 'gb_learning_rate': 0.07720142290640064, 'gb_max_depth': 8}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:35:16,896] Trial 27 finished with value: 0.6976329600351339 and parameters: {'rf_n_estimators': 101, 'rf_max_depth': 5, 'gb_n_estimators': 143, 'gb_learning_rate': 0.0784189378021611, 'gb_max_depth': 8}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:37:42,681] Trial 28 finished with value: 0.7371069389547651 and parameters: {'rf_n_estimators': 86, 'rf_max_depth': 3, 'gb_n_estimators': 165, 'gb_learning_rate': 0.09258593732429096, 'gb_max_depth': 6}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:39:17,655] Trial 29 finished with value: 0.7469128238910847 and parameters: {'rf_n_estimators': 74, 'rf_max_depth': 6, 'gb_n_estimators': 189, 'gb_learning_rate': 0.07478511902805422, 'gb_max_depth': 3}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:41:43,194] Trial 30 finished with value: 0.778594532279315 and parameters: {'rf_n_estimators': 109, 'rf_max_depth': 8, 'gb_n_estimators': 183, 'gb_learning_rate': 0.06637105151409593, 'gb_max_depth': 5}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:45:42,114] Trial 31 finished with value: 0.7947580149319279 and parameters: {'rf_n_estimators': 119, 'rf_max_depth': 7, 'gb_n_estimators': 172, 'gb_learning_rate': 0.08660767794404856, 'gb_max_depth': 10}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:49:03,995] Trial 32 finished with value: 0.7756818181818181 and parameters: {'rf_n_estimators': 119, 'rf_max_depth': 7, 'gb_n_estimators': 171, 'gb_learning_rate': 0.08245314207208883, 'gb_max_depth': 8}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:51:26,860] Trial 33 finished with value: 0.756062252964427 and parameters: {'rf_n_estimators': 94, 'rf_max_depth': 5, 'gb_n_estimators': 136, 'gb_learning_rate': 0.07777763630499222, 'gb_max_depth': 7}. Best is trial 16 with value: 0.7998480456741326.\n",
            "[I 2023-12-05 16:54:34,317] Trial 34 finished with value: 0.8183571585419411 and parameters: {'rf_n_estimators': 77, 'rf_max_depth': 6, 'gb_n_estimators': 148, 'gb_learning_rate': 0.0846649315713278, 'gb_max_depth': 9}. Best is trial 34 with value: 0.8183571585419411.\n",
            "[I 2023-12-05 16:57:43,267] Trial 35 finished with value: 0.7404397233201582 and parameters: {'rf_n_estimators': 77, 'rf_max_depth': 6, 'gb_n_estimators': 149, 'gb_learning_rate': 0.08453732369618294, 'gb_max_depth': 9}. Best is trial 34 with value: 0.8183571585419411.\n",
            "[I 2023-12-05 17:01:02,534] Trial 36 finished with value: 0.7026684233640755 and parameters: {'rf_n_estimators': 65, 'rf_max_depth': 8, 'gb_n_estimators': 158, 'gb_learning_rate': 0.07461521161527086, 'gb_max_depth': 9}. Best is trial 34 with value: 0.8183571585419411.\n",
            "[I 2023-12-05 17:04:38,260] Trial 37 finished with value: 0.7925539086517347 and parameters: {'rf_n_estimators': 166, 'rf_max_depth': 7, 'gb_n_estimators': 146, 'gb_learning_rate': 0.09166366545787827, 'gb_max_depth': 10}. Best is trial 34 with value: 0.8183571585419411.\n",
            "[I 2023-12-05 17:07:35,231] Trial 38 finished with value: 0.806814558629776 and parameters: {'rf_n_estimators': 170, 'rf_max_depth': 9, 'gb_n_estimators': 112, 'gb_learning_rate': 0.09385994388918947, 'gb_max_depth': 10}. Best is trial 34 with value: 0.8183571585419411.\n",
            "[I 2023-12-05 17:10:36,461] Trial 39 finished with value: 0.7718079710144927 and parameters: {'rf_n_estimators': 199, 'rf_max_depth': 9, 'gb_n_estimators': 113, 'gb_learning_rate': 0.09949874734398201, 'gb_max_depth': 10}. Best is trial 34 with value: 0.8183571585419411.\n",
            "[I 2023-12-05 17:13:09,104] Trial 40 finished with value: 0.7851437198067635 and parameters: {'rf_n_estimators': 167, 'rf_max_depth': 10, 'gb_n_estimators': 102, 'gb_learning_rate': 0.08198227256114718, 'gb_max_depth': 9}. Best is trial 34 with value: 0.8183571585419411.\n",
            "[I 2023-12-05 17:16:16,604] Trial 41 finished with value: 0.8064712340799296 and parameters: {'rf_n_estimators': 178, 'rf_max_depth': 8, 'gb_n_estimators': 121, 'gb_learning_rate': 0.09230460780844914, 'gb_max_depth': 10}. Best is trial 34 with value: 0.8183571585419411.\n",
            "[I 2023-12-05 17:19:23,227] Trial 42 finished with value: 0.8185209705753185 and parameters: {'rf_n_estimators': 177, 'rf_max_depth': 8, 'gb_n_estimators': 120, 'gb_learning_rate': 0.09009741056309659, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:22:34,442] Trial 43 finished with value: 0.7785205314009662 and parameters: {'rf_n_estimators': 180, 'rf_max_depth': 9, 'gb_n_estimators': 122, 'gb_learning_rate': 0.0948573151783145, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:25:12,551] Trial 44 finished with value: 0.7415322793148881 and parameters: {'rf_n_estimators': 194, 'rf_max_depth': 8, 'gb_n_estimators': 105, 'gb_learning_rate': 0.09010485009263156, 'gb_max_depth': 9}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:27:25,247] Trial 45 finished with value: 0.7659648660518226 and parameters: {'rf_n_estimators': 174, 'rf_max_depth': 9, 'gb_n_estimators': 85, 'gb_learning_rate': 0.09284694790712547, 'gb_max_depth': 9}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:30:26,660] Trial 46 finished with value: 0.7119158981115503 and parameters: {'rf_n_estimators': 157, 'rf_max_depth': 10, 'gb_n_estimators': 118, 'gb_learning_rate': 0.09987985272083585, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:33:15,754] Trial 47 finished with value: 0.7813743961352657 and parameters: {'rf_n_estimators': 188, 'rf_max_depth': 8, 'gb_n_estimators': 128, 'gb_learning_rate': 0.09594908111702871, 'gb_max_depth': 8}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:35:34,741] Trial 48 finished with value: 0.7278612209046991 and parameters: {'rf_n_estimators': 183, 'rf_max_depth': 8, 'gb_n_estimators': 90, 'gb_learning_rate': 0.08846837458557619, 'gb_max_depth': 9}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:38:56,530] Trial 49 finished with value: 0.7800297540623629 and parameters: {'rf_n_estimators': 149, 'rf_max_depth': 10, 'gb_n_estimators': 134, 'gb_learning_rate': 0.08340748700084641, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:41:03,244] Trial 50 finished with value: 0.7492947957839263 and parameters: {'rf_n_estimators': 173, 'rf_max_depth': 9, 'gb_n_estimators': 73, 'gb_learning_rate': 0.09492888791521042, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:44:02,544] Trial 51 finished with value: 0.7934999999999999 and parameters: {'rf_n_estimators': 161, 'rf_max_depth': 6, 'gb_n_estimators': 119, 'gb_learning_rate': 0.08755536761751785, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:46:46,343] Trial 52 finished with value: 0.7446306543697849 and parameters: {'rf_n_estimators': 148, 'rf_max_depth': 7, 'gb_n_estimators': 107, 'gb_learning_rate': 0.08930807403426036, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:49:28,767] Trial 53 finished with value: 0.7500411725955205 and parameters: {'rf_n_estimators': 193, 'rf_max_depth': 8, 'gb_n_estimators': 110, 'gb_learning_rate': 0.08426113964102526, 'gb_max_depth': 9}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:51:46,407] Trial 54 finished with value: 0.7520573122529643 and parameters: {'rf_n_estimators': 53, 'rf_max_depth': 7, 'gb_n_estimators': 98, 'gb_learning_rate': 0.08000313773502549, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:55:47,947] Trial 55 finished with value: 0.8121176987263944 and parameters: {'rf_n_estimators': 166, 'rf_max_depth': 8, 'gb_n_estimators': 194, 'gb_learning_rate': 0.09616616293747052, 'gb_max_depth': 9}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 17:59:23,026] Trial 56 finished with value: 0.7269340140535793 and parameters: {'rf_n_estimators': 180, 'rf_max_depth': 9, 'gb_n_estimators': 193, 'gb_learning_rate': 0.09628241024416238, 'gb_max_depth': 7}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 18:01:55,545] Trial 57 finished with value: 0.7570848704435662 and parameters: {'rf_n_estimators': 172, 'rf_max_depth': 1, 'gb_n_estimators': 131, 'gb_learning_rate': 0.09043520691032673, 'gb_max_depth': 8}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 18:05:10,864] Trial 58 finished with value: 0.7613096179183135 and parameters: {'rf_n_estimators': 163, 'rf_max_depth': 8, 'gb_n_estimators': 140, 'gb_learning_rate': 0.0944357611748501, 'gb_max_depth': 9}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 18:07:44,148] Trial 59 finished with value: 0.7295811374615722 and parameters: {'rf_n_estimators': 153, 'rf_max_depth': 5, 'gb_n_estimators': 123, 'gb_learning_rate': 0.09986156859336827, 'gb_max_depth': 8}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 18:10:30,072] Trial 60 finished with value: 0.7193148880105402 and parameters: {'rf_n_estimators': 168, 'rf_max_depth': 9, 'gb_n_estimators': 196, 'gb_learning_rate': 0.0856430926260951, 'gb_max_depth': 5}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 18:14:47,644] Trial 61 finished with value: 0.7447057531840142 and parameters: {'rf_n_estimators': 178, 'rf_max_depth': 7, 'gb_n_estimators': 179, 'gb_learning_rate': 0.08749185652489788, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 18:18:49,977] Trial 62 finished with value: 0.7806246157224417 and parameters: {'rf_n_estimators': 186, 'rf_max_depth': 8, 'gb_n_estimators': 180, 'gb_learning_rate': 0.0903064838864093, 'gb_max_depth': 9}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 18:21:40,769] Trial 63 finished with value: 0.7401590909090909 and parameters: {'rf_n_estimators': 136, 'rf_max_depth': 6, 'gb_n_estimators': 115, 'gb_learning_rate': 0.08105535530818953, 'gb_max_depth': 10}. Best is trial 42 with value: 0.8185209705753185.\n",
            "[I 2023-12-05 18:25:02,536] Trial 64 finished with value: 0.8265704874835308 and parameters: {'rf_n_estimators': 117, 'rf_max_depth': 7, 'gb_n_estimators': 153, 'gb_learning_rate': 0.0855036483139636, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:28:36,976] Trial 65 finished with value: 0.8023296003513394 and parameters: {'rf_n_estimators': 124, 'rf_max_depth': 8, 'gb_n_estimators': 164, 'gb_learning_rate': 0.09662784349677365, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:32:12,057] Trial 66 finished with value: 0.808453557312253 and parameters: {'rf_n_estimators': 146, 'rf_max_depth': 8, 'gb_n_estimators': 160, 'gb_learning_rate': 0.09642203117318127, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:35:40,590] Trial 67 finished with value: 0.7760176767676767 and parameters: {'rf_n_estimators': 144, 'rf_max_depth': 7, 'gb_n_estimators': 156, 'gb_learning_rate': 0.09379299326916875, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:38:44,661] Trial 68 finished with value: 0.7717636144049187 and parameters: {'rf_n_estimators': 158, 'rf_max_depth': 6, 'gb_n_estimators': 151, 'gb_learning_rate': 0.09678646993932984, 'gb_max_depth': 8}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:39:58,615] Trial 69 finished with value: 0.7389320377689943 and parameters: {'rf_n_estimators': 169, 'rf_max_depth': 9, 'gb_n_estimators': 141, 'gb_learning_rate': 0.09126375157237517, 'gb_max_depth': 2}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:43:35,202] Trial 70 finished with value: 0.7883902064119456 and parameters: {'rf_n_estimators': 155, 'rf_max_depth': 8, 'gb_n_estimators': 160, 'gb_learning_rate': 0.08430534662240723, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:47:07,330] Trial 71 finished with value: 0.7880648880105401 and parameters: {'rf_n_estimators': 124, 'rf_max_depth': 8, 'gb_n_estimators': 164, 'gb_learning_rate': 0.09781328347748114, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:50:29,652] Trial 72 finished with value: 0.7971702898550725 and parameters: {'rf_n_estimators': 132, 'rf_max_depth': 8, 'gb_n_estimators': 153, 'gb_learning_rate': 0.09632060249581943, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:53:26,498] Trial 73 finished with value: 0.7658881203337724 and parameters: {'rf_n_estimators': 138, 'rf_max_depth': 7, 'gb_n_estimators': 145, 'gb_learning_rate': 0.09349031207648932, 'gb_max_depth': 8}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 18:57:16,162] Trial 74 finished with value: 0.7989269872639438 and parameters: {'rf_n_estimators': 113, 'rf_max_depth': 9, 'gb_n_estimators': 168, 'gb_learning_rate': 0.09995573181064078, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:00:20,007] Trial 75 finished with value: 0.7122435221783048 and parameters: {'rf_n_estimators': 59, 'rf_max_depth': 8, 'gb_n_estimators': 133, 'gb_learning_rate': 0.09163795107060096, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:03:41,716] Trial 76 finished with value: 0.6966938954765041 and parameters: {'rf_n_estimators': 81, 'rf_max_depth': 7, 'gb_n_estimators': 160, 'gb_learning_rate': 0.08836895549883067, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:06:12,073] Trial 77 finished with value: 0.7688819718928415 and parameters: {'rf_n_estimators': 93, 'rf_max_depth': 8, 'gb_n_estimators': 125, 'gb_learning_rate': 0.09692966726202379, 'gb_max_depth': 8}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:09:18,700] Trial 78 finished with value: 0.7381699604743084 and parameters: {'rf_n_estimators': 129, 'rf_max_depth': 9, 'gb_n_estimators': 138, 'gb_learning_rate': 0.08573136761347602, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:12:12,423] Trial 79 finished with value: 0.7466652393500219 and parameters: {'rf_n_estimators': 146, 'rf_max_depth': 6, 'gb_n_estimators': 117, 'gb_learning_rate': 0.0936118284290896, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:15:34,361] Trial 80 finished with value: 0.7498618796662274 and parameters: {'rf_n_estimators': 116, 'rf_max_depth': 8, 'gb_n_estimators': 154, 'gb_learning_rate': 0.08987624297004415, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:18:16,099] Trial 81 finished with value: 0.7872882081686429 and parameters: {'rf_n_estimators': 108, 'rf_max_depth': 7, 'gb_n_estimators': 176, 'gb_learning_rate': 0.08003675204562469, 'gb_max_depth': 6}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:21:50,711] Trial 82 finished with value: 0.7077210144927536 and parameters: {'rf_n_estimators': 103, 'rf_max_depth': 8, 'gb_n_estimators': 186, 'gb_learning_rate': 0.08343535129006106, 'gb_max_depth': 8}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:24:54,694] Trial 83 finished with value: 0.6854363197189284 and parameters: {'rf_n_estimators': 126, 'rf_max_depth': 9, 'gb_n_estimators': 170, 'gb_learning_rate': 0.08735904131645675, 'gb_max_depth': 7}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:28:18,764] Trial 84 finished with value: 0.7961085858585858 and parameters: {'rf_n_estimators': 162, 'rf_max_depth': 2, 'gb_n_estimators': 161, 'gb_learning_rate': 0.09789930270671829, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:32:00,379] Trial 85 finished with value: 0.806685441370224 and parameters: {'rf_n_estimators': 176, 'rf_max_depth': 8, 'gb_n_estimators': 148, 'gb_learning_rate': 0.09308928496026814, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:35:37,584] Trial 86 finished with value: 0.8187918313570488 and parameters: {'rf_n_estimators': 177, 'rf_max_depth': 7, 'gb_n_estimators': 147, 'gb_learning_rate': 0.094638056742242, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:39:16,429] Trial 87 finished with value: 0.7980157004830917 and parameters: {'rf_n_estimators': 176, 'rf_max_depth': 7, 'gb_n_estimators': 148, 'gb_learning_rate': 0.0918631601295163, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:42:34,004] Trial 88 finished with value: 0.7923915239350021 and parameters: {'rf_n_estimators': 191, 'rf_max_depth': 6, 'gb_n_estimators': 130, 'gb_learning_rate': 0.09414865651810989, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:45:28,008] Trial 89 finished with value: 0.7150643390425999 and parameters: {'rf_n_estimators': 183, 'rf_max_depth': 7, 'gb_n_estimators': 111, 'gb_learning_rate': 0.08980673632046368, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:48:33,099] Trial 90 finished with value: 0.7297395696091349 and parameters: {'rf_n_estimators': 172, 'rf_max_depth': 7, 'gb_n_estimators': 121, 'gb_learning_rate': 0.08215526327660709, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:52:09,154] Trial 91 finished with value: 0.8181652393500218 and parameters: {'rf_n_estimators': 183, 'rf_max_depth': 8, 'gb_n_estimators': 142, 'gb_learning_rate': 0.09606079484180317, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:55:46,138] Trial 92 finished with value: 0.8019364295125164 and parameters: {'rf_n_estimators': 180, 'rf_max_depth': 8, 'gb_n_estimators': 144, 'gb_learning_rate': 0.09517902933912156, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 19:59:19,211] Trial 93 finished with value: 0.7698795564339042 and parameters: {'rf_n_estimators': 200, 'rf_max_depth': 9, 'gb_n_estimators': 137, 'gb_learning_rate': 0.0921437798487943, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 20:03:00,998] Trial 94 finished with value: 0.7928054457619675 and parameters: {'rf_n_estimators': 184, 'rf_max_depth': 8, 'gb_n_estimators': 148, 'gb_learning_rate': 0.09800829046902218, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 20:06:36,877] Trial 95 finished with value: 0.8087830478700043 and parameters: {'rf_n_estimators': 170, 'rf_max_depth': 10, 'gb_n_estimators': 143, 'gb_learning_rate': 0.08563465324267033, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 20:10:25,117] Trial 96 finished with value: 0.7666040843214758 and parameters: {'rf_n_estimators': 165, 'rf_max_depth': 10, 'gb_n_estimators': 153, 'gb_learning_rate': 0.08589451012658526, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 20:13:44,003] Trial 97 finished with value: 0.699923364075538 and parameters: {'rf_n_estimators': 170, 'rf_max_depth': 10, 'gb_n_estimators': 142, 'gb_learning_rate': 0.08877966943047882, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 20:17:34,669] Trial 98 finished with value: 0.7891060606060607 and parameters: {'rf_n_estimators': 175, 'rf_max_depth': 10, 'gb_n_estimators': 156, 'gb_learning_rate': 0.09498583862858331, 'gb_max_depth': 10}. Best is trial 64 with value: 0.8265704874835308.\n",
            "[I 2023-12-05 20:20:37,364] Trial 99 finished with value: 0.709203557312253 and parameters: {'rf_n_estimators': 191, 'rf_max_depth': 4, 'gb_n_estimators': 135, 'gb_learning_rate': 0.08652197441384803, 'gb_max_depth': 9}. Best is trial 64 with value: 0.8265704874835308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters for StackingClassifier: {'rf_n_estimators': 117, 'rf_max_depth': 7, 'gb_n_estimators': 153, 'gb_learning_rate': 0.0855036483139636, 'gb_max_depth': 9}\n",
            "AUC for Training Set: 0.6610\n",
            "AUC for Testing Set: 0.5397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to a file\n",
        "joblib.dump(stacking_classifier, 'stacking_model.joblib')\n",
        "\n",
        "# Load model and generate probability CSV\n",
        "loaded_model = joblib.load('stacking_model.joblib')\n",
        "prob = loaded_model.predict_proba(X)[:, 1]\n",
        "prob_df = pd.DataFrame(prob, columns=['Probability'])\n",
        "prob_df.index = prob_df.index + 1\n",
        "prob_df.index.name = 'Id'\n",
        "prob_df.to_csv('intento.csv', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "W5HzdhmKU0Ay",
        "outputId": "56e1e34f-8c6b-4b6c-f4d4-bfe8e661993b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-38ae7cef1a28>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the trained model to a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacking_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stacking_model.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load model and generate probability CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stacking_model.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
          ]
        }
      ]
    }
  ]
}