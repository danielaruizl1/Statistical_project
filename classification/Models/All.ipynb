{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Librerias"
      ],
      "metadata": {
        "id": "1xnILOZlXUPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, StackingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ErCJksNtXVWD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranking Original Data"
      ],
      "metadata": {
        "id": "Wr4KS_IyXXkn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AXWbQHgV-yn",
        "outputId": "eb05be88-8fe0-44b5-da3d-a455c845ff26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Gradient Boosting AUC: 0.589476426152644\n",
            "Random Forest AUC: 0.58661109663975\n",
            "Ada Boost AUC: 0.58661109663975\n",
            "Bagging AUC: 0.585178431883303\n",
            "KNN AUC: 0.5454545454545454\n",
            "Ridge Classifier AUC: 0.5454545454545454\n",
            "Stacking AUC: 0.5454545454545454\n",
            "MLP Classifier AUC: 0.5440218806980984\n",
            "Decision Tree AUC: 0.5282625683771816\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "data = pd.read_excel('TrainClass.xlsx')\n",
        "real_data = pd.read_excel('TestClass.xlsx')\n",
        "\n",
        "# Split data\n",
        "Y, X = data['FRACASO'], data.drop(['FRACASO', 'CODIGO_EMPRESA'], axis=1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "X = real_data.drop(['CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Create a list to store AUC values\n",
        "auc_list = []\n",
        "\n",
        "# Decision Tree\n",
        "arbol = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "arbol.fit(X_train, Y_train)\n",
        "y_pred_test = arbol.predict(X_test)\n",
        "auc_arbol = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Decision Tree\", auc_arbol))\n",
        "\n",
        "# Random Forest\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, Y_train)\n",
        "y_pred_test = rfc.predict(X_test)\n",
        "auc_rfc = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Random Forest\", auc_rfc))\n",
        "\n",
        "# KNN\n",
        "clf_knn = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier())])\n",
        "clf_knn.fit(X_train, Y_train)\n",
        "y_pred_test = clf_knn.predict(X_test)\n",
        "auc_knn = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"KNN\", auc_knn))\n",
        "\n",
        "# Ridge Classifier\n",
        "clf_ridge = RidgeClassifier().fit(X_train, Y_train)\n",
        "y_pred_test = clf_ridge.predict(X_test)\n",
        "auc_ridge = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ridge Classifier\", auc_ridge))\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, Y_train)\n",
        "y_pred_test = clf_gb.predict(X_test)\n",
        "auc_gb = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Gradient Boosting\", auc_gb))\n",
        "\n",
        "# Bagging\n",
        "bagging = BaggingClassifier(RandomForestClassifier())\n",
        "bagging.fit(X_train, Y_train)\n",
        "y_pred_test = bagging.predict(X_test)\n",
        "auc_bagging = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Bagging\", auc_bagging))\n",
        "\n",
        "# MLP Classifier\n",
        "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
        "clf_mlp.fit(X_train, Y_train)\n",
        "y_pred_test = clf_mlp.predict(X_test)\n",
        "auc_mlp = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"MLP Classifier\", auc_mlp))\n",
        "\n",
        "# Ada Boost\n",
        "clf_ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf_ada.fit(X_train, Y_train)\n",
        "y_pred_test = clf_ada.predict(X_test)\n",
        "auc_ada = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ada Boost\", auc_ada))\n",
        "\n",
        "# Stacking\n",
        "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "              ('gbc', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))]\n",
        "clf_stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "clf_stack.fit(X_train, Y_train)\n",
        "y_pred_test = clf_stack.predict(X_test)\n",
        "auc_stack = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Stacking\", auc_stack))\n",
        "\n",
        "# Sort and print the AUC values\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "sorted_auc_list = sorted(auc_list, key=lambda x: x[1], reverse=True)\n",
        "for model, auc_value in sorted_auc_list:\n",
        "    print(f\"{model} AUC: {auc_value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UnderSample"
      ],
      "metadata": {
        "id": "MaaEcjNmX7DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_excel('TrainClass.xlsx')\n",
        "real_data = pd.read_excel('TestClass.xlsx')\n",
        "\n",
        "# Split data\n",
        "Y, X = data['FRACASO'], data.drop(['FRACASO', 'CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Undersample the majority class\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "X_resampled, Y_resampled = rus.fit_resample(X, Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, Y_resampled, test_size=0.2, random_state=0)\n",
        "X = real_data.drop(['CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Create a list to store AUC values\n",
        "auc_list = []\n",
        "\n",
        "# Decision Tree\n",
        "arbol = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "arbol.fit(X_train, Y_train)\n",
        "y_pred_test = arbol.predict(X_test)\n",
        "auc_arbol = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Decision Tree\", auc_arbol))\n",
        "\n",
        "# Random Forest\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, Y_train)\n",
        "y_pred_test = rfc.predict(X_test)\n",
        "auc_rfc = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Random Forest\", auc_rfc))\n",
        "\n",
        "# KNN\n",
        "clf_knn = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier())])\n",
        "clf_knn.fit(X_train, Y_train)\n",
        "y_pred_test = clf_knn.predict(X_test)\n",
        "auc_knn = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"KNN\", auc_knn))\n",
        "\n",
        "# Ridge Classifier\n",
        "clf_ridge = RidgeClassifier().fit(X_train, Y_train)\n",
        "y_pred_test = clf_ridge.predict(X_test)\n",
        "auc_ridge = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ridge Classifier\", auc_ridge))\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, Y_train)\n",
        "y_pred_test = clf_gb.predict(X_test)\n",
        "auc_gb = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Gradient Boosting\", auc_gb))\n",
        "\n",
        "# Bagging\n",
        "bagging = BaggingClassifier(RandomForestClassifier())\n",
        "bagging.fit(X_train, Y_train)\n",
        "y_pred_test = bagging.predict(X_test)\n",
        "auc_bagging = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Bagging\", auc_bagging))\n",
        "\n",
        "# MLP Classifier\n",
        "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
        "clf_mlp.fit(X_train, Y_train)\n",
        "y_pred_test = clf_mlp.predict(X_test)\n",
        "auc_mlp = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"MLP Classifier\", auc_mlp))\n",
        "\n",
        "# Ada Boost\n",
        "clf_ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf_ada.fit(X_train, Y_train)\n",
        "y_pred_test = clf_ada.predict(X_test)\n",
        "auc_ada = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ada Boost\", auc_ada))\n",
        "\n",
        "# Stacking\n",
        "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "              ('gbc', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))]\n",
        "clf_stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "clf_stack.fit(X_train, Y_train)\n",
        "y_pred_test = clf_stack.predict(X_test)\n",
        "auc_stack = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Stacking\", auc_stack))\n",
        "\n",
        "# Sort and print the AUC values\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "sorted_auc_list = sorted(auc_list, key=lambda x: x[1], reverse=True)\n",
        "for model, auc_value in sorted_auc_list:\n",
        "    print(f\"{model} AUC: {auc_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYaUZKZxXayb",
        "outputId": "3e51dae5-9010-4848-ffb8-cb79432ae9b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Random Forest AUC: 0.7500000000000001\n",
            "KNN AUC: 0.7142857142857143\n",
            "Bagging AUC: 0.7142857142857143\n",
            "MLP Classifier AUC: 0.6785714285714286\n",
            "Ridge Classifier AUC: 0.6785714285714285\n",
            "Stacking AUC: 0.6785714285714285\n",
            "Decision Tree AUC: 0.6428571428571428\n",
            "Gradient Boosting AUC: 0.6428571428571428\n",
            "Ada Boost AUC: 0.6428571428571428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OverSample"
      ],
      "metadata": {
        "id": "6vZDDlRUX85G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_excel('TrainClass.xlsx')\n",
        "real_data = pd.read_excel('TestClass.xlsx')\n",
        "\n",
        "# Split data\n",
        "Y, X = data['FRACASO'], data.drop(['FRACASO', 'CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Oversample the minority class\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "X_resampled, Y_resampled = ros.fit_resample(X, Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, Y_resampled, test_size=0.2, random_state=0)\n",
        "X = real_data.drop(['CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Create a list to store AUC values\n",
        "auc_list = []\n",
        "\n",
        "# Decision Tree\n",
        "arbol = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "arbol.fit(X_train, Y_train)\n",
        "y_pred_test = arbol.predict(X_test)\n",
        "auc_arbol = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Decision Tree\", auc_arbol))\n",
        "\n",
        "# Random Forest\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, Y_train)\n",
        "y_pred_test = rfc.predict(X_test)\n",
        "auc_rfc = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Random Forest\", auc_rfc))\n",
        "\n",
        "# KNN\n",
        "clf_knn = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier())])\n",
        "clf_knn.fit(X_train, Y_train)\n",
        "y_pred_test = clf_knn.predict(X_test)\n",
        "auc_knn = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"KNN\", auc_knn))\n",
        "\n",
        "# Ridge Classifier\n",
        "clf_ridge = RidgeClassifier().fit(X_train, Y_train)\n",
        "y_pred_test = clf_ridge.predict(X_test)\n",
        "auc_ridge = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ridge Classifier\", auc_ridge))\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, Y_train)\n",
        "y_pred_test = clf_gb.predict(X_test)\n",
        "auc_gb = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Gradient Boosting\", auc_gb))\n",
        "\n",
        "# Bagging\n",
        "bagging = BaggingClassifier(RandomForestClassifier())\n",
        "bagging.fit(X_train, Y_train)\n",
        "y_pred_test = bagging.predict(X_test)\n",
        "auc_bagging = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Bagging\", auc_bagging))\n",
        "\n",
        "# MLP Classifier\n",
        "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
        "clf_mlp.fit(X_train, Y_train)\n",
        "y_pred_test = clf_mlp.predict(X_test)\n",
        "auc_mlp = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"MLP Classifier\", auc_mlp))\n",
        "\n",
        "# Ada Boost\n",
        "clf_ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf_ada.fit(X_train, Y_train)\n",
        "y_pred_test = clf_ada.predict(X_test)\n",
        "auc_ada = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ada Boost\", auc_ada))\n",
        "\n",
        "# Stacking\n",
        "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "              ('gbc', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))]\n",
        "clf_stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "clf_stack.fit(X_train, Y_train)\n",
        "y_pred_test = clf_stack.predict(X_test)\n",
        "auc_stack = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Stacking\", auc_stack))\n",
        "\n",
        "# Sort and print the AUC values\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "sorted_auc_list = sorted(auc_list, key=lambda x: x[1], reverse=True)\n",
        "for model, auc_value in sorted_auc_list:\n",
        "    print(f\"{model} AUC: {auc_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZXRyCzhX-Jx",
        "outputId": "2ab9f2d9-20cb-4620-d911-ad2a6224bb52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Random Forest AUC: 0.9958563535911602\n",
            "Stacking AUC: 0.9958563535911602\n",
            "Bagging AUC: 0.9861878453038674\n",
            "Decision Tree AUC: 0.9792817679558011\n",
            "Gradient Boosting AUC: 0.9765193370165746\n",
            "Ada Boost AUC: 0.9751381215469613\n",
            "KNN AUC: 0.9640883977900552\n",
            "Ridge Classifier AUC: 0.7688180143981249\n",
            "MLP Classifier AUC: 0.7522769127741503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE"
      ],
      "metadata": {
        "id": "WpEdqkoQYCuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_excel('TrainClass.xlsx')\n",
        "real_data = pd.read_excel('TestClass.xlsx')\n",
        "\n",
        "# Split data\n",
        "Y, X = data['FRACASO'], data.drop(['FRACASO', 'CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=0)\n",
        "X_resampled, Y_resampled = smote.fit_resample(X, Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, Y_resampled, test_size=0.2, random_state=0)\n",
        "X = real_data.drop(['CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Create a list to store AUC values\n",
        "auc_list = []\n",
        "\n",
        "# Decision Tree\n",
        "arbol = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "arbol.fit(X_train, Y_train)\n",
        "y_pred_test = arbol.predict(X_test)\n",
        "auc_arbol = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Decision Tree\", auc_arbol))\n",
        "\n",
        "# Random Forest\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, Y_train)\n",
        "y_pred_test = rfc.predict(X_test)\n",
        "auc_rfc = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Random Forest\", auc_rfc))\n",
        "\n",
        "# KNN\n",
        "clf_knn = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier())])\n",
        "clf_knn.fit(X_train, Y_train)\n",
        "y_pred_test = clf_knn.predict(X_test)\n",
        "auc_knn = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"KNN\", auc_knn))\n",
        "\n",
        "# Ridge Classifier\n",
        "clf_ridge = RidgeClassifier().fit(X_train, Y_train)\n",
        "y_pred_test = clf_ridge.predict(X_test)\n",
        "auc_ridge = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ridge Classifier\", auc_ridge))\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, Y_train)\n",
        "y_pred_test = clf_gb.predict(X_test)\n",
        "auc_gb = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Gradient Boosting\", auc_gb))\n",
        "\n",
        "# Bagging\n",
        "bagging = BaggingClassifier(RandomForestClassifier())\n",
        "bagging.fit(X_train, Y_train)\n",
        "y_pred_test = bagging.predict(X_test)\n",
        "auc_bagging = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Bagging\", auc_bagging))\n",
        "\n",
        "# MLP Classifier\n",
        "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
        "clf_mlp.fit(X_train, Y_train)\n",
        "y_pred_test = clf_mlp.predict(X_test)\n",
        "auc_mlp = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"MLP Classifier\", auc_mlp))\n",
        "\n",
        "# Ada Boost\n",
        "clf_ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf_ada.fit(X_train, Y_train)\n",
        "y_pred_test = clf_ada.predict(X_test)\n",
        "auc_ada = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ada Boost\", auc_ada))\n",
        "\n",
        "# Stacking\n",
        "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "              ('gbc', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))]\n",
        "clf_stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "clf_stack.fit(X_train, Y_train)\n",
        "y_pred_test = clf_stack.predict(X_test)\n",
        "auc_stack = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Stacking\", auc_stack))\n",
        "\n",
        "# Sort and print the AUC values\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "sorted_auc_list = sorted(auc_list, key=lambda x: x[1], reverse=True)\n",
        "for model, auc_value in sorted_auc_list:\n",
        "    print(f\"{model} AUC: {auc_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl9IXNhiYFQ6",
        "outputId": "1904c4dd-8e84-4429-bc60-c40f85727372"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Random Forest AUC: 0.9704587309559685\n",
            "Bagging AUC: 0.9606562866231375\n",
            "Stacking AUC: 0.9574920475472961\n",
            "Decision Tree AUC: 0.9276829064121882\n",
            "KNN AUC: 0.9128494893688264\n",
            "Gradient Boosting AUC: 0.9041101623974552\n",
            "Ada Boost AUC: 0.8973798761091578\n",
            "MLP Classifier AUC: 0.8341955466264858\n",
            "Ridge Classifier AUC: 0.7725179976561192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADASYN"
      ],
      "metadata": {
        "id": "QkXoI0-5Yo24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_excel('TrainClass.xlsx')\n",
        "real_data = pd.read_excel('TestClass.xlsx')\n",
        "\n",
        "# Split data\n",
        "Y, X = data['FRACASO'], data.drop(['FRACASO', 'CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Apply ADASYN\n",
        "adasyn = ADASYN(random_state=0)\n",
        "X_resampled, Y_resampled = adasyn.fit_resample(X, Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, Y_resampled, test_size=0.2, random_state=0)\n",
        "X = real_data.drop(['CODIGO_EMPRESA'], axis=1)\n",
        "\n",
        "# Create a list to store AUC values\n",
        "auc_list = []\n",
        "\n",
        "# Decision Tree\n",
        "arbol = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "arbol.fit(X_train, Y_train)\n",
        "y_pred_test = arbol.predict(X_test)\n",
        "auc_arbol = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Decision Tree\", auc_arbol))\n",
        "\n",
        "# Random Forest\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, Y_train)\n",
        "y_pred_test = rfc.predict(X_test)\n",
        "auc_rfc = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Random Forest\", auc_rfc))\n",
        "\n",
        "# KNN\n",
        "clf_knn = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier())])\n",
        "clf_knn.fit(X_train, Y_train)\n",
        "y_pred_test = clf_knn.predict(X_test)\n",
        "auc_knn = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"KNN\", auc_knn))\n",
        "\n",
        "# Ridge Classifier\n",
        "clf_ridge = RidgeClassifier().fit(X_train, Y_train)\n",
        "y_pred_test = clf_ridge.predict(X_test)\n",
        "auc_ridge = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ridge Classifier\", auc_ridge))\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, Y_train)\n",
        "y_pred_test = clf_gb.predict(X_test)\n",
        "auc_gb = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Gradient Boosting\", auc_gb))\n",
        "\n",
        "# Bagging\n",
        "bagging = BaggingClassifier(RandomForestClassifier())\n",
        "bagging.fit(X_train, Y_train)\n",
        "y_pred_test = bagging.predict(X_test)\n",
        "auc_bagging = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Bagging\", auc_bagging))\n",
        "\n",
        "# MLP Classifier\n",
        "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
        "clf_mlp.fit(X_train, Y_train)\n",
        "y_pred_test = clf_mlp.predict(X_test)\n",
        "auc_mlp = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"MLP Classifier\", auc_mlp))\n",
        "\n",
        "# Ada Boost\n",
        "clf_ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf_ada.fit(X_train, Y_train)\n",
        "y_pred_test = clf_ada.predict(X_test)\n",
        "auc_ada = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Ada Boost\", auc_ada))\n",
        "\n",
        "# Stacking\n",
        "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "              ('gbc', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))]\n",
        "clf_stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "clf_stack.fit(X_train, Y_train)\n",
        "y_pred_test = clf_stack.predict(X_test)\n",
        "auc_stack = roc_auc_score(Y_test, y_pred_test)\n",
        "auc_list.append((\"Stacking\", auc_stack))\n",
        "\n",
        "# Sort and print the AUC values\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "sorted_auc_list = sorted(auc_list, key=lambda x: x[1], reverse=True)\n",
        "for model, auc_value in sorted_auc_list:\n",
        "    print(f\"{model} AUC: {auc_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se1eHBPWYqAp",
        "outputId": "9da8cea2-6046-41a1-c7d0-6b20610d20ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Random Forest AUC: 0.9689034369885433\n",
            "Stacking AUC: 0.9573299041384148\n",
            "Bagging AUC: 0.9535012859480945\n",
            "Decision Tree AUC: 0.9247135842880524\n",
            "Gradient Boosting AUC: 0.9128477905073649\n",
            "KNN AUC: 0.9021802665419687\n",
            "Ada Boost AUC: 0.9019172317044657\n",
            "MLP Classifier AUC: 0.8588087444470424\n",
            "Ridge Classifier AUC: 0.7324058919803601\n"
          ]
        }
      ]
    }
  ]
}